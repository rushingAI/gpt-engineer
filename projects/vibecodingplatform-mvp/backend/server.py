"""
Vibecoding Platform MVP - Backend Server

This FastAPI server wraps gpt-engineer's core functionality to expose
code generation capabilities via REST API.
"""

import os
import tempfile
from pathlib import Path
from typing import Dict, List, Any
import json
import asyncio
import fnmatch

from fastapi import FastAPI, Body, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥ gpt-engineer æ ¸å¿ƒæ¨¡å—
from gpt_engineer.core.ai import AI
from gpt_engineer.core.default.steps import gen_code
from gpt_engineer.core.prompt import Prompt
from gpt_engineer.core.default.disk_memory import DiskMemory
from gpt_engineer.core.preprompts_holder import PrepromptsHolder
from gpt_engineer.core.default.paths import PREPROMPTS_PATH
from langchain_core.messages import HumanMessage

# å¯¼å…¥æ¨¡æ¿ç®¡ç†å™¨å’Œè‡ªå®šä¹‰ preprompts
from template_manager import template_manager
from preprompt_manager import custom_preprompts_manager
from dependency_detector import detect_dependencies_in_files
from dependency_arbiter import arbiter, print_arbitration_summary
from style_selector import select_style_deterministic, get_template_for_style
from policies import policy_manager
from spec_generator import (
    generate_interaction_spec_prompt,
    validate_and_repair_spec,
    create_spec_summary
)
from quality_gates import run_quality_gates
from self_heal import should_trigger_self_heal, self_heal_loop
from l0_gates import run_l0_gates
from prompt_fragments import (
    build_base_rules,
    build_dynamic_rules,
    format_spec_payload,
    format_file_manifest,
    format_files_content,
    get_policy_version,
    log_prompt_telemetry,
    compute_prompt_hash,
    get_locked_paths,
    get_allowed_paths,
    get_entrypoints_hint
)

app = FastAPI(
    title="Vibecoding Platform API",
    description="AI-powered code generation service",
    version="0.1.0"
)

# é…ç½® CORS - å…è®¸å‰ç«¯è·¨åŸŸè®¿é—®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ– gpt-engineer ç»„ä»¶
# æ£€æŸ¥ API key
if not os.getenv("OPENAI_API_KEY") and not os.getenv("ANTHROPIC_API_KEY"):
    print("è­¦å‘Š: æœªæ‰¾åˆ° OPENAI_API_KEY æˆ– ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")

try:
    ai = AI(
        model_name=os.getenv("MODEL_NAME", "GPT-5.1-Codex-Max"),
        temperature=0.1
    )
    preprompts_holder = PrepromptsHolder(PREPROMPTS_PATH)
    print(f"âœ“ AI åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹: {ai.model_name}")
except Exception as e:
    print(f"âœ— AI åˆå§‹åŒ–å¤±è´¥: {e}")
    ai = None
    preprompts_holder = None


@app.get("/")
def root():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "running",
        "message": "Vibecoding Platform API",
        "ai_ready": ai is not None,
        "features": {
            "template_mode": True,
            "traditional_mode": True,
            "available_templates": len(template_manager.list_templates())
        }
    }


@app.get("/templates")
def list_templates():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡æ¿"""
    templates = template_manager.list_templates()
    return {
        "templates": templates,
        "count": len(templates)
    }


@app.post("/generate")
def generate_app(
    prompt_text: str = Body(..., embed=True),
    use_template: bool = Body(default=True, embed=True),
    template_name: str = Body(default=None, embed=True),
    style: str = Body(default="auto", embed=True)
) -> Dict[str, str]:
    """
    æ ¹æ®è‡ªç„¶è¯­è¨€æç¤ºè¯ç”Ÿæˆåº”ç”¨ä»£ç 
    
    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. ä¼ ç»Ÿæ¨¡å¼ï¼ˆuse_template=Falseï¼‰: ä»é›¶å¼€å§‹ç”Ÿæˆï¼Œç”Ÿæˆå•æ–‡ä»¶ HTML
    2. æ¨¡æ¿æ¨¡å¼ï¼ˆuse_template=Trueï¼‰: åŸºäº React + TypeScript æ¨¡æ¿ç”Ÿæˆç°ä»£åŒ–åº”ç”¨
    
    Args:
        prompt_text: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æè¿°
        use_template: æ˜¯å¦ä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿï¼ˆé»˜è®¤ Trueï¼‰
        template_name: æ¨¡æ¿åç§°ï¼ˆå¯é€‰ï¼Œä¼šè‡ªåŠ¨æ£€æµ‹ï¼‰
        style: è§†è§‰é£æ ¼ï¼ˆauto/cyberpunk/aurora/glass/neo_brutal/minimal/retro_futurismï¼Œé»˜è®¤ autoï¼‰
        
    Returns:
        Dict[str, str]: æ–‡ä»¶ååˆ°æ–‡ä»¶å†…å®¹çš„æ˜ å°„å­—å…¸
        
    Example:
        POST /generate
        {
            "prompt_text": "åˆ›å»ºä¸€ä¸ªç°ä»£åŒ–çš„ landing page",
            "use_template": true,
            "style": "auto"
        }
    """
    if ai is None:
        raise HTTPException(
            status_code=503,
            detail="AI æœåŠ¡æœªå°±ç»ªï¼Œè¯·æ£€æŸ¥ API key é…ç½®"
        )
    
    if not prompt_text or not prompt_text.strip():
        raise HTTPException(
            status_code=400,
            detail="prompt_text ä¸èƒ½ä¸ºç©º"
        )
    
    try:
        prompt_text = prompt_text.strip()
        print(f"ğŸ“ æ”¶åˆ°ç”Ÿæˆè¯·æ±‚: {prompt_text[:100]}...")
        print(f"   æ¨¡å¼: {'æ¨¡æ¿æ¨¡å¼' if use_template else 'ä¼ ç»Ÿæ¨¡å¼'}")
        
        if use_template:
            # æ¨¡æ¿æ¨¡å¼ï¼šç”Ÿæˆç°ä»£åŒ–çš„ React åº”ç”¨
            return generate_with_template(prompt_text, template_name, style)
        else:
            # ä¼ ç»Ÿæ¨¡å¼ï¼šä½¿ç”¨åŸå§‹çš„ gpt-engineer æµç¨‹
            return generate_traditional(prompt_text)
            
    except Exception as e:
        print(f"âœ— ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"ä»£ç ç”Ÿæˆå¤±è´¥: {str(e)}"
        )


def generate_traditional(prompt_text: str) -> Dict[str, str]:
    """ä¼ ç»Ÿç”Ÿæˆæ¨¡å¼ï¼šä»é›¶å¼€å§‹ç”Ÿæˆï¼ˆé€šå¸¸æ˜¯å•æ–‡ä»¶ HTMLï¼‰"""
    with tempfile.TemporaryDirectory() as tmp_dir:
        memory = DiskMemory(tmp_dir)
        prompt = Prompt(prompt_text)
        
        # ä½¿ç”¨åŸå§‹çš„ gpt-engineer preprompts
        files_dict = gen_code(ai, prompt, memory, preprompts_holder)
        
        print(f"âœ“ ä¼ ç»Ÿæ¨¡å¼ç”Ÿæˆå®Œæˆï¼Œå…± {len(files_dict)} ä¸ªæ–‡ä»¶")
        return dict(files_dict)


def fix_component_imports(code: str) -> str:
    """
    ä¿®æ­£å¸¸è§çš„ç»„ä»¶å¯¼å…¥è·¯å¾„é”™è¯¯
    shadcn/ui ç»„ä»¶æ–‡ä»¶åæ˜¯å°å†™çš„ï¼Œä½† AI ç»å¸¸ä¼šä½¿ç”¨å¤§å†™
    """
    import re
    
    # å®šä¹‰éœ€è¦ä¿®æ­£çš„ç»„ä»¶åˆ—è¡¨ï¼ˆå¤§å†™ -> å°å†™ï¼‰
    components_to_fix = [
        'Button', 'Card', 'Input', 'Textarea', 'Tabs', 'TabsList', 'TabsTrigger', 'TabsContent',
        'Separator', 'ScrollArea', 'Dialog', 'Select', 'Label', 'Checkbox', 'RadioGroup',
        'Switch', 'Slider', 'Progress', 'Avatar', 'Badge', 'Alert', 'Toast', 'Tooltip',
        'DropdownMenu', 'Popover', 'HoverCard', 'NavigationMenu', 'Command', 'Calendar',
        'Sheet', 'Accordion', 'AspectRatio', 'Collapsible', 'ContextMenu', 'Menubar',
        'CardHeader', 'CardContent', 'CardFooter', 'CardTitle', 'CardDescription'
    ]
    
    fixed_code = code
    
    # ä¿®æ­£æ¯ä¸ªç»„ä»¶çš„å¯¼å…¥è·¯å¾„
    for component in components_to_fix:
        component_lower = component.lower()
        
        # ä¿®æ­£å•ç‹¬å¯¼å…¥: from '@/components/ui/Button'
        pattern1 = rf"from ['\"]@/components/ui/{component}['\"]"
        replacement1 = f"from '@/components/ui/{component_lower}'"
        fixed_code = re.sub(pattern1, replacement1, fixed_code, flags=re.IGNORECASE)
        
        # ä¿®æ­£å¸¦æ–‡ä»¶æ‰©å±•åçš„: from '@/components/ui/Button.tsx'
        pattern2 = rf"from ['\"]@/components/ui/{component}\.tsx['\"]"
        replacement2 = f"from '@/components/ui/{component_lower}'"
        fixed_code = re.sub(pattern2, replacement2, fixed_code, flags=re.IGNORECASE)
    
    return fixed_code


def fix_lucide_icons(code: str) -> str:
    """
    ä¿®æ­£ lucide-react å›¾æ ‡å¯¼å…¥é”™è¯¯
    AI ç»å¸¸ä¼šåˆ›é€ ä¸å­˜åœ¨çš„å›¾æ ‡åç§°ï¼Œè¿™é‡Œæ›¿æ¢æˆçœŸå®çš„å›¾æ ‡
    """
    import re
    
    # æ£€æµ‹æ— æ•ˆçš„å›¾æ ‡å¯¼å…¥æ¨¡å¼
    # ä¾‹å¦‚: import { FeatureIcon1, Icon1, FeatureIcon } from 'lucide-react'
    invalid_icon_patterns = [
        r'FeatureIcon\d*', r'Icon\d+', r'FeatureIcon', r'TestimonialIcon',
        r'HeroIcon', r'CardIcon', r'SectionIcon'
    ]
    
    # çœŸå®çš„å¸¸ç”¨å›¾æ ‡æ›¿æ¢
    real_icons = ['Zap', 'Star', 'Heart', 'Sparkles', 'Rocket', 'Shield']
    
    # æŸ¥æ‰¾ lucide-react å¯¼å…¥è¡Œ
    lucide_import_pattern = r"import\s*\{([^}]+)\}\s*from\s*['\"]lucide-react['\"]"
    
    def replace_invalid_icons(match):
        imports = match.group(1)
        import_list = [i.strip() for i in imports.split(',')]
        
        fixed_imports = []
        icon_index = 0
        
        for imp in import_list:
            is_invalid = False
            for pattern in invalid_icon_patterns:
                if re.match(pattern, imp):
                    is_invalid = True
                    break
            
            if is_invalid:
                # ç”¨çœŸå®å›¾æ ‡æ›¿æ¢
                if icon_index < len(real_icons):
                    fixed_imports.append(real_icons[icon_index])
                    icon_index += 1
            else:
                fixed_imports.append(imp)
        
        return f"import {{ {', '.join(fixed_imports)} }} from 'lucide-react'"
    
    fixed_code = re.sub(lucide_import_pattern, replace_invalid_icons, code)
    
    # åŒæ—¶æ›¿æ¢ä½¿ç”¨è¿™äº›å›¾æ ‡çš„åœ°æ–¹
    for i, real_icon in enumerate(real_icons):
        for pattern in invalid_icon_patterns:
            # æ›¿æ¢å˜é‡ä½¿ç”¨: icon: FeatureIcon1 -> icon: Zap
            fixed_code = re.sub(
                rf'\bicon:\s*{pattern}\b',
                f'icon: {real_icons[i % len(real_icons)]}',
                fixed_code
            )
    
    return fixed_code


def generate_with_template(prompt_text: str, template_name: str = None, style: str = "auto") -> Dict[str, str]:
    """æ¨¡æ¿ç”Ÿæˆæ¨¡å¼ï¼šåŸºäº React + TypeScript æ¨¡æ¿ç”Ÿæˆ"""
    
    # 1. é€‰æ‹©é£æ ¼ï¼ˆdeterministicï¼‰
    selected_style, style_source, style_metadata = select_style_deterministic(prompt_text, style)
    print(f"   é£æ ¼é€‰æ‹©: {selected_style} (æ¥æº: {style_source})")
    if style_metadata:
        print(f"   é£æ ¼å…ƒæ•°æ®: {style_metadata}")
    
    # 2. æ£€æµ‹åº”ç”¨ç±»å‹
    app_type = custom_preprompts_manager.detect_app_type(prompt_text)
    print(f"   åº”ç”¨ç±»å‹: {app_type}")
    
    # 3. é€‰æ‹©æ¨¡æ¿ï¼ˆä¼˜å…ˆç”¨æˆ·æŒ‡å®šï¼Œå¦åˆ™æ ¹æ®é£æ ¼é€‰æ‹©ï¼‰
    if template_name is None:
        template_name = get_template_for_style(selected_style)
    print(f"   ä½¿ç”¨æ¨¡æ¿: {template_name}")
    
    # 4. åŠ è½½æ¨¡æ¿
    template = template_manager.get_template(template_name)
    if template is None:
        raise Exception(f"æ¨¡æ¿ä¸å­˜åœ¨: {template_name}")
    
    # 5. æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯ï¼ˆåŸºäºé£æ ¼å’Œåº”ç”¨ç±»å‹ï¼‰
    system_prompt = custom_preprompts_manager.build_system_prompt(app_type, selected_style)
    
    # 5.5. Spec-first: ç”Ÿæˆ InteractionSpecï¼ˆå¦‚æœå¯ç”¨ï¼‰
    interaction_spec = None
    spec_status = "disabled"
    
    if policy_manager.is_spec_first_enabled():
        print("   ğŸ¯ Spec-first æ¨¡å¼å·²å¯ç”¨ï¼Œæ­£åœ¨ç”Ÿæˆ InteractionSpec...")
        
        # ç”Ÿæˆ Spec çš„ prompt
        spec_prompt = generate_interaction_spec_prompt(prompt_text, app_type)
        
        # è°ƒç”¨ AI ç”Ÿæˆ Spec
        messages = ai.next(
            messages=[HumanMessage(content=spec_prompt)],
            step_name="generate_interaction_spec"
        )
        
        # è·å– AI çš„å“åº”ï¼ˆæœ€åä¸€æ¡æ¶ˆæ¯ï¼‰
        spec_text = messages[-1].content
        
        # éªŒè¯å¹¶ä¿®å¤ Spec
        interaction_spec, spec_status = validate_and_repair_spec(ai, spec_text)
        
        if interaction_spec is None:
            print(f"   âœ— Spec ç”Ÿæˆå¤±è´¥: {spec_status}")
            # å¦‚æœ Spec ç”Ÿæˆå¤±è´¥ï¼Œå¯ä»¥é€‰æ‹©é™çº§åˆ°é Spec æ¨¡å¼ï¼Œæˆ–è€…ç›´æ¥å¤±è´¥
            # è¿™é‡Œæˆ‘ä»¬é€‰æ‹©é™çº§ï¼ˆè­¦å‘Šä½†ç»§ç»­ï¼‰
            print("   âš ï¸  é™çº§åˆ°é Spec æ¨¡å¼ç»§ç»­ç”Ÿæˆ")
        else:
            print(f"   âœ“ InteractionSpec ç”ŸæˆæˆåŠŸ (çŠ¶æ€: {spec_status})")
            print(f"     - State: {len(interaction_spec.get('state', []))} ä¸ª")
            print(f"     - Events: {len(interaction_spec.get('events', []))} ä¸ª")
            print(f"     - Constraints: {len(interaction_spec.get('constraints', []))} ä¸ª")
            print(f"     - Acceptance: {len(interaction_spec.get('acceptance', []))} ä¸ª")
    
    # 6. æ„å»ºç”¨æˆ·æç¤ºè¯ï¼ˆä½¿ç”¨æ–°çš„æ¨¡å—åŒ– prompt ç‰‡æ®µï¼‰
    
    # 6.1 BaseRulesï¼ˆçŸ­ç¡¬å¯æ‰§è¡Œï¼‰
    base_rules = build_base_rules(mode='generate')
    
    # 6.2 DynamicRulesï¼ˆåŸºäºä¸Šä¸‹æ–‡è§¦å‘ï¼‰
    dynamic_context = {
        'gate_results': {},  # ç”Ÿæˆé˜¶æ®µæš‚æ— é—¨ç¦ç»“æœ
        'files': {},
        'prompt_text': prompt_text,
        'interaction_spec': interaction_spec
    }
    dynamic_rules, activated_rule_ids = build_dynamic_rules(dynamic_context)
    
    # 6.3 Spec è½½è·ï¼ˆä¼˜å…ˆæ‘˜è¦ï¼‰
    spec_section, spec_mode = format_spec_payload(interaction_spec, prefer_summary=True)
    
    # 6.4 æ„å»ºå¢å¼ºçš„ prompt
    enhanced_prompt = f"""{system_prompt}
{spec_section}

================================================================================
USER REQUEST:
================================================================================

{prompt_text}

================================================================================
{base_rules}

{dynamic_rules}

OUTPUT FORMAT:
You MUST output files in this EXACT format:

FILENAME
```
CODE
```

DO NOT use markdown headings (###), language tags, or descriptions!
Just: FILENAME then ``` CODE ```

ALLOWED FILE LOCATIONS:
- src/pages/Index.tsx (main entry, use default export)
- src/components/generated/<appSlug>/*.tsx (domain components)
- src/lib/generated/*.ts (pure logic, NO JSX)

YOU ARE WORKING WITH:
- Pre-configured React + TypeScript + Vite + Tailwind + shadcn/ui
- BrowserRouter already in src/main.tsx
- Global styles in src/index.css (do not modify)
- Import shadcn components from @/components/ui/ (lowercase paths)
- Import icons from lucide-react
"""
    
    # 7. è®°å½• prompt é¥æµ‹
    log_prompt_telemetry(
        prompt=enhanced_prompt,
        mode='generate',
        activated_fragments=activated_rule_ids,
        spec_mode=spec_mode,
        context={'policy_version': get_policy_version()}
    )
    
    # 8. è°ƒç”¨ AI ç”Ÿæˆä»£ç 
    with tempfile.TemporaryDirectory() as tmp_dir:
        memory = DiskMemory(tmp_dir)
        prompt = Prompt(enhanced_prompt)
        
        # ä½¿ç”¨åŸå§‹çš„ preprompts_holderï¼ˆç”¨äºæ–‡ä»¶æ ¼å¼ç­‰åŸºç¡€æŒ‡å¯¼ï¼‰
        generated_files = gen_code(ai, prompt, memory, preprompts_holder)
        
        print(f"   AI ç”Ÿæˆäº† {len(generated_files)} ä¸ªæ–‡ä»¶")
        
        # 9. åå¤„ç†ï¼šä¿®æ­£ç»„ä»¶å¯¼å…¥è·¯å¾„å’Œå›¾æ ‡å¯¼å…¥
        fixed_generated_files = {}
        component_fixes = 0
        icon_fixes = 0
        
        for filename, content in generated_files.items():
            if filename.endswith(('.tsx', '.ts', '.jsx', '.js')):
                original_content = content
                
                # ä¿®æ­£ç»„ä»¶å¯¼å…¥è·¯å¾„
                fixed_content = fix_component_imports(content)
                if fixed_content != original_content:
                    component_fixes += 1
                    print(f"   âš ï¸  ä¿®æ­£äº† {filename} ä¸­çš„ç»„ä»¶å¯¼å…¥è·¯å¾„")
                
                # ä¿®æ­£å›¾æ ‡å¯¼å…¥
                original_after_component_fix = fixed_content
                fixed_content = fix_lucide_icons(fixed_content)
                if fixed_content != original_after_component_fix:
                    icon_fixes += 1
                    print(f"   âš ï¸  ä¿®æ­£äº† {filename} ä¸­çš„å›¾æ ‡å¯¼å…¥")
                
                fixed_generated_files[filename] = fixed_content
            else:
                fixed_generated_files[filename] = content
        
        if component_fixes > 0:
            print(f"   âœ“ è‡ªåŠ¨ä¿®æ­£äº† {component_fixes} ä¸ªæ–‡ä»¶çš„ç»„ä»¶å¯¼å…¥è·¯å¾„")
        if icon_fixes > 0:
            print(f"   âœ“ è‡ªåŠ¨ä¿®æ­£äº† {icon_fixes} ä¸ªæ–‡ä»¶çš„å›¾æ ‡å¯¼å…¥")
        
        # 10. æ£€æµ‹ç”Ÿæˆä»£ç ä¸­çš„é¢å¤–ä¾èµ–å¹¶ä»²è£ï¼ˆä¸ç›´æ¥ä¿®æ”¹ package.jsonï¼‰
        requested_deps = detect_dependencies_in_files(fixed_generated_files)
        approved_deps = {}
        rejected_deps = {}
        dep_warnings = []
        
        if requested_deps:
            print(f"\n   ğŸ” æ£€æµ‹åˆ° {len(requested_deps)} ä¸ªé¢å¤–ä¾èµ–è¯·æ±‚ï¼Œæäº¤ä»²è£...")
            approved_deps, rejected_deps, dep_warnings = arbiter.arbitrate(requested_deps)
            print_arbitration_summary(approved_deps, rejected_deps, dep_warnings)
        
        # 11. åˆå¹¶æ¨¡æ¿å’Œç”Ÿæˆçš„æ–‡ä»¶
        template_files = template['files']
        
        # âš ï¸ package.json å—ä¿æŠ¤ï¼Œä¸å†ç”± AI ç›´æ¥ä¿®æ”¹
        # æ‰¹å‡†çš„ä¾èµ–å°†è®°å½•åœ¨ vibe.meta.json ä¸­ï¼Œç”±å‰ç«¯/WebContainer åŠ¨æ€æ³¨å…¥
        
        final_files = template_manager.merge_files(template_files, fixed_generated_files)
        
        # 11.1. æå‰åˆ›å»º vibe.meta.jsonï¼ˆè‡³å°‘åŒ…å«ä¾èµ–ä¿¡æ¯ï¼‰ï¼Œä»¥ä¾¿é—¨ç¦æ£€æŸ¥
        # è¿™æ · _check_dependency_consistency å°±èƒ½æ­£å¸¸å·¥ä½œ
        preliminary_vibe_meta = {
            "dependencies": arbiter.create_dependency_report(
                requested_deps if requested_deps else {},
                approved_deps if approved_deps else {},
                rejected_deps if rejected_deps else {}
            )
        }
        final_files['vibe.meta.json'] = json.dumps(preliminary_vibe_meta, indent=2, ensure_ascii=False)
        
        # 11.2. è¿è¡Œ L0 äº¤äº’/æ ·å¼é—¨ç¦ï¼ˆé’ˆå¯¹ç»“æ„æ€§åº”ç”¨ï¼‰
        l0_config = policy_manager._policy.get('l0_style_gates', {})
        l0_context = {
            'prompt_text': prompt_text,
            'app_type': app_type,
            'interaction_spec': interaction_spec,
            'generated_file_paths': list(final_files.keys())
        }
        l0_result = run_l0_gates(final_files, l0_context, l0_config)
        
        # æ‰“å° L0 é—¨ç¦ç»“æœï¼ˆä¾¿äºè°ƒè¯•ï¼‰
        if not l0_result.to_dict()['pass']:
            print(f"\n   ğŸš¨ L0 äº¤äº’/æ ·å¼é—¨ç¦å¤±è´¥:")
            for fail in l0_result.fails:
                print(f"     âœ— {fail['gate']}: {fail['message']}")
                print(f"       æ¶‰åŠæ–‡ä»¶: {', '.join(fail['files'][:3])}")
                if fail.get('suggestion'):
                    print(f"       å»ºè®®: {fail['suggestion'][:100]}")
        if l0_result.warnings:
            print(f"\n   âš ï¸  L0 äº¤äº’/æ ·å¼é—¨ç¦è­¦å‘Š ({len(l0_result.warnings)} ä¸ª):")
            for warn in l0_result.warnings[:3]:
                print(f"     - {warn['gate']}: {warn['message']}")
        if l0_result.hints:
            for hint in l0_result.hints[:2]:
                print(f"   ğŸ’¡ {hint}")
        
        # 11.3. è¿è¡Œè´¨é‡é—¨ç¦ï¼ˆæœ€å¿«å¤±è´¥ä¼˜å…ˆï¼‰
        gate_results = run_quality_gates(final_files)
        
        # 11.3.5. å¦‚æœ L0 å¤±è´¥ï¼Œå°†å…¶æ˜ å°„åˆ°é—¨ç¦ç»“æœï¼ˆè§¦å‘è‡ªæ„ˆï¼‰
        if not l0_result.to_dict()['pass']:
            # åˆ›å»ºä¸€ä¸ªä¼ª GateResult å¯¹è±¡ç”¨äºè‡ªæ„ˆæµç¨‹
            from quality_gates import GateResult
            l0_gate_issues = []
            for fail in l0_result.fails:
                l0_gate_issues.append({
                    'rule_id': fail['gate'],
                    'severity': 'error',
                    'file': fail['files'][0] if fail['files'] else 'unknown',
                    'line': 0,
                    'message': fail['message'],
                    'snippet': fail.get('snippet', ''),
                    'suggestion': fail.get('suggestion', '')
                })
            gate_results['L0_style_interaction'] = GateResult('L0_style_interaction', False, l0_gate_issues)
        
        # 11.4. è‡ªæ„ˆå¾ªç¯ï¼ˆå¦‚æœé—¨ç¦å¤±è´¥ï¼‰
        heal_iterations = 0
        heal_success = False
        heal_triggered = False
        
        if should_trigger_self_heal(gate_results):
            heal_triggered = True
            print(f"   ğŸ”§ è§¦å‘è‡ªæ„ˆå¾ªç¯...")
            final_files, heal_success, heal_iterations = self_heal_loop(
                ai,
                final_files,
                gate_results,
                interaction_spec
            )
            
            if heal_success:
                print(f"   âœ“ è‡ªæ„ˆæˆåŠŸï¼")
                # é‡æ–°è¿è¡Œé—¨ç¦ä»¥è·å–æœ€ç»ˆç»“æœ
                gate_results = run_quality_gates(final_files)
            else:
                print(f"   âœ— è‡ªæ„ˆå¤±è´¥ï¼Œè¿”å›æœ€åä¸€æ¬¡è¿­ä»£çš„ç»“æœ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é—¨ç¦å¤±è´¥
        failed_gates = [name for name, result in gate_results.items() if not result.passed]
        if failed_gates:
            print(f"   âš ï¸  è´¨é‡é—¨ç¦å¤±è´¥: {', '.join(failed_gates)}")
            # æ³¨æ„ï¼šå³ä½¿å¤±è´¥ï¼Œä¹Ÿè¿”å›ç»“æœï¼ˆç”¨æˆ·å¯ä»¥çœ‹åˆ°è­¦å‘Šå¹¶æ‰‹åŠ¨ä¿®å¤ï¼‰
        
        # 11.5. å¦‚æœæœ‰ InteractionSpecï¼Œå†™å…¥æ–‡ä»¶
        if interaction_spec is not None:
            spec_location = policy_manager.get_spec_location()
            final_files[spec_location] = json.dumps(interaction_spec, indent=2, ensure_ascii=False)
            print(f"   âœ“ InteractionSpec å·²å†™å…¥: {spec_location}")
        
        # 12. æ›´æ–° vibe.meta.jsonï¼ˆæ·»åŠ å®Œæ•´çš„å…ƒæ•°æ®å’Œ telemetry ä¿¡æ¯ï¼‰
        # æ³¨æ„ï¼švibe.meta.json åœ¨ç¬¬ 11.1 æ­¥å·²ç»åˆ›å»ºï¼ˆåŒ…å« dependenciesï¼‰ï¼Œç°åœ¨æ·»åŠ å…¶ä»–å­—æ®µ
        vibe_meta = {
            "style": selected_style,
            "style_source": style_source,
            "template_name": template_name,
            "app_type": app_type,
            "metadata": style_metadata,
            "generated_at": __import__('datetime').datetime.now().isoformat(),
            # ä¾èµ–ä»²è£ç»“æœï¼ˆå·²åœ¨ 11.1 æ­¥å†™å…¥ï¼Œè¿™é‡Œä¿æŒä¸€è‡´ï¼‰
            "dependencies": arbiter.create_dependency_report(
                requested_deps if requested_deps else {},
                approved_deps if approved_deps else {},
                rejected_deps if rejected_deps else {}
            ),
            # Telemetryï¼ˆç­–ç•¥ç‰ˆæœ¬ä¸ prompt å“ˆå¸Œï¼‰
            "telemetry": {
                "policy_version": get_policy_version(),
                "prompt_hash": compute_prompt_hash(enhanced_prompt),
                "prompt_length": len(enhanced_prompt),
                "activated_dynamic_rules": activated_rule_ids,
                "spec_mode": spec_mode
            }
        }
        
        # æ·»åŠ  Spec æ‘˜è¦åˆ° vibe.meta.json
        if interaction_spec is not None:
            vibe_meta["interaction_spec"] = {
                "enabled": True,
                "status": spec_status,
                "location": policy_manager.get_spec_location(),
                "summary": create_spec_summary(interaction_spec)
            }
        else:
            vibe_meta["interaction_spec"] = {
                "enabled": policy_manager.is_spec_first_enabled(),
                "status": spec_status
            }
        
        # æ·»åŠ è´¨é‡é—¨ç¦ç»“æœåˆ° vibe.meta.json
        if gate_results:
            vibe_meta["quality_gates"] = {
                "enabled": policy_manager.is_quality_gates_enabled(),
                "results": {name: result.to_dict() for name, result in gate_results.items()},
                "passed": all(result.passed for result in gate_results.values()),
                "failed_gates": [name for name, result in gate_results.items() if not result.passed]
            }
        else:
            vibe_meta["quality_gates"] = {
                "enabled": policy_manager.is_quality_gates_enabled(),
                "passed": True
            }
        
        # æ·»åŠ è‡ªæ„ˆå¾ªç¯ç»“æœåˆ° vibe.meta.json
        vibe_meta["self_heal"] = {
            "enabled": policy_manager.is_self_heal_enabled(),
            "triggered": heal_triggered,
            "success": heal_success if heal_triggered else None,
            "iterations": heal_iterations if heal_triggered else 0,
            "max_iterations": policy_manager.get_max_heal_iterations()
        }
        
        final_files['vibe.meta.json'] = json.dumps(vibe_meta, indent=2, ensure_ascii=False)
        
        print(f"âœ“ æ¨¡æ¿æ¨¡å¼ç”Ÿæˆå®Œæˆï¼Œæœ€ç»ˆ {len(final_files)} ä¸ªæ–‡ä»¶ï¼ˆå« vibe.meta.jsonï¼‰")
        
        return final_files


def improve_stage_a_select_files(
    files: Dict[str, str],
    improvement_request: str,
    ai
) -> Dict[str, Any]:
    """
    æ”¹è¿›é˜¶æ®µ Aï¼šé€‰æ‹©éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶
    
    Returns:
        {
            "selected": [{"path": str, "reason": str, "edit_scope": str}],
            "not_selected_reasoning": str,
            "needs_dependency": [{"name": str, "why": str}]
        }
    """
    # ç”Ÿæˆæ–‡ä»¶æ¸…å•
    manifest = format_file_manifest(files)
    
    # è·å–çº¦æŸ
    allowed_paths = get_allowed_paths()
    locked_paths = get_locked_paths()
    entrypoints_hint = get_entrypoints_hint()
    
    # æ„å»ºé˜¶æ®µ A prompt
    stage_a_prompt = f"""You are analyzing which files need modification for an improvement request.

IMPROVEMENT REQUEST:
{improvement_request}

FILE MANIFEST:
{json.dumps(manifest, indent=2, ensure_ascii=False)}

CONSTRAINTS:
- Allowed paths: {', '.join(allowed_paths)}
- Locked paths (DO NOT select): {', '.join(locked_paths)}
- Entry points hint: {', '.join(entrypoints_hint)}

OUTPUT STRICT JSON (NO OTHER TEXT):
{{
  "selected": [
    {{"path": "src/pages/Index.tsx", "reason": "needs UI change", "edit_scope": "modify existing component"}},
    ...
  ],
  "not_selected_reasoning": "why other files were not selected",
  "needs_dependency": [
    {{"name": "some-package", "why": "required for new feature"}},
    ...
  ]
}}

RULES:
1. Select ONLY files that need modification
2. DO NOT select locked files
3. Prefer entry points and related components
4. Keep selection minimal (usually 1-3 files)
5. Output ONLY valid JSON (no markdown, noèª¬æ˜)

Analyze and output JSON now:"""
    
    # è°ƒç”¨ AI
    with tempfile.TemporaryDirectory() as tmp_dir:
        memory = DiskMemory(tmp_dir)
        prompt = Prompt(stage_a_prompt)
        
        messages = ai.next(
            messages=[HumanMessage(content=stage_a_prompt)],
            step_name="improve_stage_a_select_files"
        )
        
        response_text = messages[-1].content
        
        # è§£æ JSON å“åº”
        try:
            # å°è¯•æå– JSONï¼ˆå¯èƒ½è¢«åŒ…è£¹åœ¨ markdown ä¸­ï¼‰
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                response_text = json_match.group(0)
            
            selection = json.loads(response_text)
            
            # è¿‡æ»¤æ‰ locked æ–‡ä»¶
            filtered_selected = []
            for item in selection.get('selected', []):
                file_path = item.get('path', '')
                is_locked = any(
                    fnmatch.fnmatch(file_path, pattern) for pattern in locked_paths
                )
                if not is_locked:
                    filtered_selected.append(item)
                else:
                    print(f"   âš ï¸  è¿‡æ»¤äº† locked æ–‡ä»¶: {file_path}")
            
            selection['selected'] = filtered_selected
            return selection
            
        except Exception as e:
            print(f"   âœ— é˜¶æ®µ A JSON è§£æå¤±è´¥: {e}")
            print(f"   å“åº”å†…å®¹: {response_text[:200]}")
            # é™çº§ï¼šé€‰æ‹©å…¥å£æ–‡ä»¶
            return {
                "selected": [
                    {"path": "src/pages/Index.tsx", "reason": "fallback to entry point", "edit_scope": "modify"}
                ],
                "not_selected_reasoning": "JSON parse failed, using fallback",
                "needs_dependency": []
            }


def improve_stage_b_apply_changes(
    files: Dict[str, str],
    improvement_request: str,
    selected_files: List[Dict[str, Any]],
    ai,
    preprompts_holder
) -> Dict[str, str]:
    """
    æ”¹è¿›é˜¶æ®µ Bï¼šå¯¹é€‰ä¸­çš„æ–‡ä»¶æ‰§è¡Œæ”¹è¿›
    
    Returns:
        æ”¹è¿›åçš„æ–‡ä»¶å­—å…¸
    """
    selected_paths = [item['path'] for item in selected_files]
    
    # åªä¼ é€‰ä¸­æ–‡ä»¶çš„å†…å®¹
    selected_content = format_files_content(files, selected_paths)
    
    # æ„å»ºé˜¶æ®µ B promptï¼ˆä½¿ç”¨ BaseRulesï¼‰
    base_rules = build_base_rules(mode='improve')
    
    stage_b_prompt = f"""You are improving selected files in a React + TypeScript application.

IMPROVEMENT REQUEST:
{improvement_request}

SELECTED FILES FOR MODIFICATION:
{json.dumps(selected_files, indent=2, ensure_ascii=False)}

CURRENT CONTENT OF SELECTED FILES:
{selected_content}

{base_rules}

OUTPUT FORMAT:
filename.tsx
```
COMPLETE FILE CONTENT
```

YOU ARE WORKING WITH:
- React + TypeScript + Vite + Tailwind + shadcn/ui
- Import shadcn from @/components/ui/ (lowercase)
- Keep all configuration files unchanged

Output ALL modified files with COMPLETE content:"""
    
    # è®°å½• telemetry
    log_prompt_telemetry(
        prompt=stage_b_prompt,
        mode='improve',
        activated_fragments=[],
        spec_mode='none',
        context={
            'policy_version': get_policy_version(),
            'selected_files': selected_paths
        }
    )
    
    # è°ƒç”¨ AI
    with tempfile.TemporaryDirectory() as tmp_dir:
        memory = DiskMemory(tmp_dir)
        prompt = Prompt(stage_b_prompt)
        improved_files = gen_code(ai, prompt, memory, preprompts_holder)
    
    return improved_files


@app.post("/improve")
def improve_code(
    files: Dict[str, str] = Body(...),
    improvement_request: str = Body(...)
) -> Dict[str, str]:
    """
    æ”¹è¿›å·²ç”Ÿæˆçš„ä»£ç ï¼ˆä¸¤é˜¶æ®µæµç¨‹ï¼‰
    
    Args:
        files: å½“å‰çš„æ–‡ä»¶å­—å…¸
        improvement_request: æ”¹è¿›è¦æ±‚
        
    Returns:
        Dict[str, str]: æ”¹è¿›åçš„æ–‡ä»¶å­—å…¸
    """
    if ai is None:
        raise HTTPException(
            status_code=503,
            detail="AI æœåŠ¡æœªå°±ç»ª"
        )
    
    try:
        # æ£€æµ‹é¡¹ç›®ç±»å‹
        is_react_project = any(
            'package.json' in f or f.endswith('.tsx') or f.endswith('.jsx')
            for f in files.keys()
        )
        
        print(f"ğŸ“ æ”¶åˆ°æ”¹è¿›è¯·æ±‚: {improvement_request[:100]}...")
        print(f"   é¡¹ç›®ç±»å‹: {'React' if is_react_project else 'é™æ€ HTML'}")
        
        if not is_react_project:
            # é™æ€ HTML é¡¹ç›®ï¼šä½¿ç”¨åŸå§‹æµç¨‹ï¼ˆæ— éœ€ä¸¤é˜¶æ®µï¼‰
            files_content = "\n\n".join([
                f"{filename}\n```\n{content}\n```"
                for filename, content in files.items()
            ])
            
            enhanced_prompt = f"""ä»¥ä¸‹æ˜¯å½“å‰çš„ä»£ç ï¼š

{files_content}

ç”¨æˆ·çš„æ”¹è¿›è¦æ±‚ï¼š{improvement_request}

è¯·æä¾›æ”¹è¿›åçš„å®Œæ•´ä»£ç ã€‚è¦æ±‚ï¼š
- ä¿æŒ HTML/CSS/JavaScript çš„ Web åº”ç”¨æ ¼å¼
- åªä¿®æ”¹éœ€è¦æ”¹è¿›çš„éƒ¨åˆ†
- ä¿æŒæ–‡ä»¶ç»“æ„ä¸å˜

è¾“å‡ºæ ¼å¼ï¼š
FILENAME
```
CODE
```
"""
            
            with tempfile.TemporaryDirectory() as tmp_dir:
                memory = DiskMemory(tmp_dir)
                prompt = Prompt(enhanced_prompt)
                improved_files = gen_code(ai, prompt, memory, preprompts_holder)
            
            print(f"âœ“ æ”¹è¿›å®Œæˆï¼Œå…± {len(improved_files)} ä¸ªæ–‡ä»¶")
            return dict(improved_files)
        
        # React é¡¹ç›®ï¼šä½¿ç”¨ä¸¤é˜¶æ®µæµç¨‹
        print(f"   ğŸ” é˜¶æ®µ A: é€‰æ‹©éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶...")
        selection = improve_stage_a_select_files(files, improvement_request, ai)
        
        selected_count = len(selection['selected'])
        print(f"   âœ“ é˜¶æ®µ A å®Œæˆ: é€‰ä¸­ {selected_count} ä¸ªæ–‡ä»¶")
        for item in selection['selected']:
            print(f"     - {item['path']}: {item['reason']}")
        
        if selected_count == 0:
            print(f"   âš ï¸  æ²¡æœ‰æ–‡ä»¶è¢«é€‰ä¸­ï¼Œè¿”å›åŸå§‹æ–‡ä»¶")
            return files
        
        print(f"   ğŸ”§ é˜¶æ®µ B: æ‰§è¡Œæ”¹è¿›...")
        improved_files = improve_stage_b_apply_changes(
            files,
            improvement_request,
            selection['selected'],
            ai,
            preprompts_holder
        )
        
        print(f"   AI è¿”å›äº† {len(improved_files)} ä¸ªæ–‡ä»¶")
        
        # æ£€æµ‹æ–°å¢çš„ä¾èµ–å¹¶ä»²è£
        requested_deps = detect_dependencies_in_files(improved_files)
        approved_deps = {}
        rejected_deps = {}
        
        if requested_deps:
            print(f"   ğŸ” æ£€æµ‹åˆ° {len(requested_deps)} ä¸ªæ–°ä¾èµ–ï¼Œæäº¤ä»²è£...")
            approved_deps, rejected_deps, dep_warnings = arbiter.arbitrate(requested_deps)
            print_arbitration_summary(approved_deps, rejected_deps, dep_warnings)
        
        # åˆå¹¶æ–‡ä»¶
        result = dict(files)  # å¤åˆ¶åŸæ–‡ä»¶
        result.update(improved_files)  # æ›´æ–°ä¿®æ”¹çš„æ–‡ä»¶
        
        # æ›´æ–° vibe.meta.jsonï¼ˆåˆå¹¶ä¾èµ–ä¿¡æ¯ï¼‰
        if approved_deps or requested_deps:
            vibe_meta = {}
            if 'vibe.meta.json' in result:
                try:
                    vibe_meta = json.loads(result['vibe.meta.json'])
                except:
                    pass
            
            # åˆå¹¶ä¾èµ–ä¿¡æ¯
            existing_deps = vibe_meta.get('dependencies', {})
            updated_report = arbiter.create_dependency_report(
                requested_deps,
                approved_deps,
                rejected_deps
            )
            
            # åˆå¹¶æ‰¹å‡†çš„ä¾èµ–ï¼ˆä¿ç•™æ—§çš„ + æ–°çš„ï¼‰
            all_approved = existing_deps.get('approved', {}) if isinstance(existing_deps, dict) else {}
            all_approved.update(approved_deps)
            updated_report['approved'] = all_approved
            
            vibe_meta['dependencies'] = updated_report
            vibe_meta['last_improved_at'] = __import__('datetime').datetime.now().isoformat()
            
            result['vibe.meta.json'] = json.dumps(vibe_meta, indent=2, ensure_ascii=False)
            print(f"   âœ“ å·²æ›´æ–° vibe.meta.jsonï¼ˆç´¯è®¡æ‰¹å‡†ä¾èµ–: {len(all_approved)}ï¼‰")
        
        print(f"âœ“ æ”¹è¿›å®Œæˆï¼Œæœ€ç»ˆ {len(result)} ä¸ªæ–‡ä»¶")
        return result
        
    except Exception as e:
        print(f"âœ— æ”¹è¿›å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"ä»£ç æ”¹è¿›å¤±è´¥: {str(e)}"
        )


@app.post("/generate-stream")
async def generate_app_stream(
    prompt_text: str = Body(..., embed=True),
    use_template: bool = Body(default=True, embed=True),
    template_name: str = Body(default=None, embed=True),
    style: str = Body(default="auto", embed=True)
):
    """
    æµå¼ç”Ÿæˆåº”ç”¨ä»£ç  (SSE)
    
    è¿”å› Server-Sent Events æµï¼Œå®æ—¶æ¨é€ç”Ÿæˆè¿›åº¦
    """
    if ai is None:
        raise HTTPException(
            status_code=503,
            detail="AI æœåŠ¡æœªå°±ç»ªï¼Œè¯·æ£€æŸ¥ API key é…ç½®"
        )
    
    if not prompt_text or not prompt_text.strip():
        raise HTTPException(
            status_code=400,
            detail="prompt_text ä¸èƒ½ä¸ºç©º"
        )
    
    async def event_generator():
        try:
            prompt_text_clean = prompt_text.strip()
            
            # æ­¥éª¤ 1: å‘é€åˆ†æçŠ¶æ€
            yield f"data: {json.dumps({'type': 'status', 'content': 'æ­£åœ¨åˆ†æéœ€æ±‚...'})}\n\n"
            await asyncio.sleep(0.1)
            
            # æ­¥éª¤ 2: æ£€æµ‹åº”ç”¨ç±»å‹å’Œæ¨¡æ¿
            if use_template:
                app_type = custom_preprompts_manager.detect_app_type(prompt_text_clean)
                detected_template = template_name or template_manager.detect_template_type(prompt_text_clean)
                
                yield f"data: {json.dumps({'type': 'status', 'content': f'ä½¿ç”¨æ¨¡æ¿: {detected_template}'})}\n\n"
                await asyncio.sleep(0.1)
                
                # æ­¥éª¤ 3: ç”Ÿæˆä»£ç 
                yield f"data: {json.dumps({'type': 'status', 'content': 'æ­£åœ¨ç”Ÿæˆä»£ç ...'})}\n\n"
                
                # è°ƒç”¨ç”Ÿæˆå‡½æ•°
                files_dict = await asyncio.to_thread(
                    generate_with_template, 
                    prompt_text_clean, 
                    detected_template,
                    style
                )
                
                # æ­¥éª¤ 4: å‘é€æ–‡ä»¶ç”Ÿæˆäº‹ä»¶
                for filename in files_dict.keys():
                    yield f"data: {json.dumps({'type': 'file', 'filename': filename})}\n\n"
                    await asyncio.sleep(0.05)  # å°å»¶è¿Ÿè®©å‰ç«¯æœ‰æ—¶é—´æ¸²æŸ“
                
                # æ­¥éª¤ 5: å‘é€å®Œæˆäº‹ä»¶
                yield f"data: {json.dumps({'type': 'complete', 'files': files_dict, 'filesCount': len(files_dict)})}\n\n"
                
            else:
                # ä¼ ç»Ÿæ¨¡å¼
                yield f"data: {json.dumps({'type': 'status', 'content': 'æ­£åœ¨ç”Ÿæˆä»£ç ...'})}\n\n"
                
                files_dict = await asyncio.to_thread(
                    generate_traditional,
                    prompt_text_clean
                )
                
                for filename in files_dict.keys():
                    yield f"data: {json.dumps({'type': 'file', 'filename': filename})}\n\n"
                    await asyncio.sleep(0.05)
                
                yield f"data: {json.dumps({'type': 'complete', 'files': files_dict, 'filesCount': len(files_dict)})}\n\n"
            
        except Exception as e:
            print(f"âœ— æµå¼ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨ nginx ç¼“å†²
        }
    )


@app.post("/improve-stream")
async def improve_code_stream(
    files: Dict[str, str] = Body(...),
    improvement_request: str = Body(...)
):
    """
    æµå¼æ”¹è¿›å·²ç”Ÿæˆçš„ä»£ç  (SSE)
    
    è¿”å› Server-Sent Events æµï¼Œå®æ—¶æ¨é€æ”¹è¿›è¿›åº¦
    """
    if ai is None:
        raise HTTPException(
            status_code=503,
            detail="AI æœåŠ¡æœªå°±ç»ª"
        )
    
    async def event_generator():
        try:
            # æ£€æµ‹é¡¹ç›®ç±»å‹
            is_react_project = any(
                'package.json' in f or f.endswith('.tsx') or f.endswith('.jsx')
                for f in files.keys()
            )
            
            if not is_react_project:
                # é™æ€ HTML é¡¹ç›®ï¼šä½¿ç”¨åŸå§‹æµç¨‹
                yield f"data: {json.dumps({'type': 'status', 'content': 'æ­£åœ¨åˆ†ææ”¹è¿›éœ€æ±‚...'})}\n\n"
                await asyncio.sleep(0.1)
                
                yield f"data: {json.dumps({'type': 'status', 'content': 'æ­£åœ¨ä¼˜åŒ–ä»£ç ...'})}\n\n"
                
                files_content = "\n\n".join([
                    f"{filename}\n```\n{content}\n```"
                    for filename, content in files.items()
                ])
                
                enhanced_prompt = f"""ä»¥ä¸‹æ˜¯å½“å‰çš„ä»£ç ï¼š

{files_content}

ç”¨æˆ·çš„æ”¹è¿›è¦æ±‚ï¼š{improvement_request}

è¯·æä¾›æ”¹è¿›åçš„å®Œæ•´ä»£ç ã€‚è¦æ±‚ï¼š
- ä¿æŒ HTML/CSS/JavaScript çš„ Web åº”ç”¨æ ¼å¼
- åªä¿®æ”¹éœ€è¦æ”¹è¿›çš„éƒ¨åˆ†
- ä¿æŒæ–‡ä»¶ç»“æ„ä¸å˜

è¾“å‡ºæ ¼å¼ï¼š
FILENAME
```
CODE
```
"""
                
                with tempfile.TemporaryDirectory() as tmp_dir:
                    memory = DiskMemory(tmp_dir)
                    prompt = Prompt(enhanced_prompt)
                    improved_files = await asyncio.to_thread(
                        gen_code, ai, prompt, memory, preprompts_holder
                    )
                
                for filename in improved_files.keys():
                    yield f"data: {json.dumps({'type': 'file', 'filename': filename})}\n\n"
                    await asyncio.sleep(0.05)
                
                yield f"data: {json.dumps({'type': 'complete', 'files': dict(improved_files), 'filesCount': len(improved_files)})}\n\n"
                return
            
            # React é¡¹ç›®ï¼šä½¿ç”¨ä¸¤é˜¶æ®µæµç¨‹
            # æ­¥éª¤ 1: é˜¶æ®µ A - é€‰æ‹©æ–‡ä»¶
            yield f"data: {json.dumps({'type': 'status', 'content': 'æ­£åœ¨åˆ†æéœ€è¦ä¿®æ”¹çš„æ–‡ä»¶...'})}\n\n"
            await asyncio.sleep(0.1)
            
            selection = await asyncio.to_thread(
                improve_stage_a_select_files,
                files,
                improvement_request,
                ai
            )
            
            selected_count = len(selection['selected'])
            
            if selected_count == 0:
                yield f"data: {json.dumps({'type': 'status', 'content': 'æ²¡æœ‰æ–‡ä»¶éœ€è¦ä¿®æ”¹'})}\n\n"
                yield f"data: {json.dumps({'type': 'complete', 'files': files, 'filesCount': len(files)})}\n\n"
                return
            
            # æ­¥éª¤ 2: æ¨é€é€‰ä¸­çš„æ–‡ä»¶
            yield f"data: {json.dumps({'type': 'status', 'content': f'é€‰ä¸­äº† {selected_count} ä¸ªæ–‡ä»¶è¿›è¡Œä¿®æ”¹'})}\n\n"
            await asyncio.sleep(0.1)
            
            for item in selection['selected']:
                yield f"data: {json.dumps({'type': 'selected_file', 'path': item['path'], 'reason': item['reason']})}\n\n"
                await asyncio.sleep(0.05)
            
            # æ­¥éª¤ 3: é˜¶æ®µ B - æ‰§è¡Œæ”¹è¿›
            yield f"data: {json.dumps({'type': 'status', 'content': 'æ­£åœ¨ä¼˜åŒ–ä»£ç ...'})}\n\n"
            await asyncio.sleep(0.1)
            
            improved_files = await asyncio.to_thread(
                improve_stage_b_apply_changes,
                files,
                improvement_request,
                selection['selected'],
                ai,
                preprompts_holder
            )
            
            # æ­¥éª¤ 4: æ£€æµ‹å’Œä»²è£æ–°ä¾èµ–
            requested_deps = detect_dependencies_in_files(improved_files)
            approved_deps = {}
            rejected_deps = {}
            
            if requested_deps:
                yield f"data: {json.dumps({'type': 'status', 'content': f'æ£€æµ‹åˆ° {len(requested_deps)} ä¸ªæ–°ä¾èµ–ï¼Œæ­£åœ¨ä»²è£...'})}\n\n"
                approved_deps, rejected_deps, dep_warnings = arbiter.arbitrate(requested_deps)
                print_arbitration_summary(approved_deps, rejected_deps, dep_warnings)
            
            # æ­¥éª¤ 5: åˆå¹¶æ–‡ä»¶
            result = dict(files)
            result.update(improved_files)
            
            # æ›´æ–° vibe.meta.json
            if approved_deps or requested_deps:
                vibe_meta = {}
                if 'vibe.meta.json' in result:
                    try:
                        vibe_meta = json.loads(result['vibe.meta.json'])
                    except:
                        pass
                
                existing_deps = vibe_meta.get('dependencies', {})
                updated_report = arbiter.create_dependency_report(
                    requested_deps,
                    approved_deps,
                    rejected_deps
                )
                
                # åˆå¹¶æ‰¹å‡†çš„ä¾èµ–
                all_approved = existing_deps.get('approved', {}) if isinstance(existing_deps, dict) else {}
                all_approved.update(approved_deps)
                updated_report['approved'] = all_approved
                
                vibe_meta['dependencies'] = updated_report
                vibe_meta['last_improved_at'] = __import__('datetime').datetime.now().isoformat()
                
                result['vibe.meta.json'] = json.dumps(vibe_meta, indent=2, ensure_ascii=False)
            
            # æ­¥éª¤ 7: å‘é€æ–‡ä»¶æ›´æ–°äº‹ä»¶
            for filename in improved_files.keys():
                yield f"data: {json.dumps({'type': 'file', 'filename': filename})}\n\n"
                await asyncio.sleep(0.05)
            
            # æ­¥éª¤ 8: å‘é€å®Œæˆäº‹ä»¶
            yield f"data: {json.dumps({'type': 'complete', 'files': result, 'filesCount': len(result)})}\n\n"
            
        except Exception as e:
            print(f"âœ— æµå¼æ”¹è¿›å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.get("/health")
def health_check():
    """è¯¦ç»†çš„å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "ai_initialized": ai is not None,
        "model": ai.model_name if ai else None,
        "preprompts_loaded": preprompts_holder is not None,
        "api_keys_configured": {
            "openai": bool(os.getenv("OPENAI_API_KEY")),
            "anthropic": bool(os.getenv("ANTHROPIC_API_KEY"))
        }
    }


if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨ Vibecoding Platform åç«¯æœåŠ¡...")
    print("ğŸ“– API æ–‡æ¡£: http://localhost:8000/docs")
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)

