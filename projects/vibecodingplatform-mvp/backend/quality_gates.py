"""
è´¨é‡é—¨ç¦ - æ£€æµ‹ç”Ÿæˆä»£ç çš„äº¤äº’æ€§é—®é¢˜
"""
import re
from typing import Dict, List, Tuple, Any
from policies import policy_manager


class GateResult:
    """é—¨ç¦æ£€æŸ¥ç»“æœ"""
    
    def __init__(self, level: str, passed: bool, issues: List[Dict[str, Any]] = None):
        self.level = level
        self.passed = passed
        self.issues = issues or []
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "level": self.level,
            "passed": self.passed,
            "issues_count": len(self.issues),
            "issues": self.issues
        }


class L0StaticGate:
    """
    L0 é™æ€é—¸é—¨ - AST/Regex æ··åˆæ‰«æ
    æ£€æµ‹ 5 ç±»é«˜é¢‘äº¤äº’æ€§é—®é¢˜
    """
    
    def __init__(self):
        self.rules = policy_manager.get_static_gate_rules()
    
    def check(self, files: Dict[str, str]) -> GateResult:
        """
        æ£€æŸ¥æ–‡ä»¶ä¸­çš„é™æ€é—®é¢˜
        
        Args:
            files: æ–‡ä»¶å­—å…¸ {filename: content}
            
        Returns:
            GateResult
        """
        issues = []
        
        # åªæ£€æŸ¥ä¸šåŠ¡ä»£ç æ–‡ä»¶ï¼Œæ’é™¤ UI åº“ç»„ä»¶å’Œé…ç½®æ–‡ä»¶
        excluded_patterns = [
            'src/components/ui/',      # UI åº“ç»„ä»¶
            'src/lib/utils',           # å·¥å…·å‡½æ•°
            'tailwind.config',         # é…ç½®æ–‡ä»¶
            'vite.config',
            'tsconfig',
            'postcss.config',
            'package.json',
            'vibe.meta.json',
        ]
        
        react_files = {}
        for filename, content in files.items():
            if filename.endswith(('.tsx', '.jsx', '.ts', '.js')):
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
                should_exclude = any(pattern in filename for pattern in excluded_patterns)
                if not should_exclude:
                    react_files[filename] = content
        
        for filename, content in react_files.items():
            # è·³è¿‡è§„åˆ™ 1-2ï¼ˆå·²ç”±æ–°çš„ Gate4/Gate5 æ£€æŸ¥ï¼‰
            # issues.extend(self._check_controlled_input_missing_onchange(filename, content))
            # issues.extend(self._check_readonly_wrong_condition(filename, content))
            
            # è§„åˆ™ 3: onClick handler å†…æ— çŠ¶æ€æ›´æ–°ï¼ˆL0StaticGate ç‹¬æœ‰ï¼‰
            issues.extend(self._check_onclick_no_state_update(filename, content))
            
            # è§„åˆ™ 4: ç©º handler æˆ– TODOï¼ˆL0StaticGate ç‹¬æœ‰ï¼‰
            issues.extend(self._check_empty_handler(filename, content))
            
            # è·³è¿‡è§„åˆ™ 5ï¼ˆè¾ƒæ¨¡ç³Šï¼Œäº¤ç»™æ–°é—¨ç¦ï¼‰
            # issues.extend(self._check_no_state_management(filename, content))
        
            # è§„åˆ™ 6: å¯¼å…¥è¾¹ç•Œè¿è§„ï¼ˆL0StaticGate ç‹¬æœ‰ï¼Œé‡è¦ï¼‰
            issues.extend(self._check_import_boundary_violation(filename, content))
            
            # è§„åˆ™ 7: Index.tsx è¿‡å¤§ï¼ˆL0StaticGate ç‹¬æœ‰ï¼Œé‡è¦ï¼‰
            if 'Index.tsx' in filename:
                issues.extend(self._check_index_too_large(filename, content))
        
             # è§„åˆ™ 8: è¾“å…¥æ¡†æ–‡å­—å¯¹æ¯”åº¦æ£€æŸ¥ï¼ˆé˜²æ­¢æ–‡å­—ä¸èƒŒæ™¯è‰²å†²çªï¼‰
            issues.extend(self._check_input_text_contrast(filename, content))
             
             # è§„åˆ™ 9: æ–‡æœ¬å…ƒç´ æ˜¾å¼é¢œè‰²æ£€æŸ¥ï¼ˆé˜²æ­¢ä¾èµ–å…¨å±€ç»§æ‰¿ï¼‰
            issues.extend(self._check_missing_text_color(filename, content))
             
             # è§„åˆ™ 10: å¯¹æ¯”åº¦é—®é¢˜æ£€æŸ¥ï¼ˆé˜²æ­¢æ·±è‰²onæ·±è‰²/æµ…è‰²onæµ…è‰²ï¼‰
            issues.extend(self._check_text_contrast_issues(filename, content))
            
            # è§„åˆ™ 11: API ä½¿ç”¨é”™è¯¯æ£€æµ‹ï¼ˆé˜²æ­¢æ··æ·†ä¸åŒåº“çš„ APIï¼‰
            issues.extend(self._check_api_usage_errors(filename, content))
        
        # è§„åˆ™ 12: å¯¼å‡ºä¸€è‡´æ€§æ£€æŸ¥ï¼ˆæ–°å¢ï¼Œé‡è¦ï¼‰
        issues.extend(self._check_export_consistency(files))
        
        # è§„åˆ™ 13: å¯¼å…¥å¯¼å‡ºåŒ¹é…æ£€æŸ¥ï¼ˆé˜²æ­¢ Index.tsx å¯¼å…¥ä¸å­˜åœ¨çš„å¯¼å‡ºï¼‰
        issues.extend(self._check_import_export_consistency(files))
        
        # è§„åˆ™ 14: ä¾èµ–ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆç¡®ä¿ä¾èµ–ä¿¡æ¯æ­£ç¡®å†™å…¥ï¼‰
        issues.extend(self._check_dependency_consistency(files))
        
        # è§„åˆ™ 15: é‡å¤å®šä¹‰æ£€æµ‹ï¼ˆé˜²æ­¢åŒä¸€å‡½æ•°å®šä¹‰å¤šæ¬¡ï¼‰
        issues.extend(self._check_duplicate_definitions(files))
        
        # è§„åˆ™ 16: æ•°æ®å¥‘çº¦æ£€æµ‹ï¼ˆé˜²æ­¢è¿”å›æ•°æ®ç¼ºå°‘å¿…éœ€å­—æ®µï¼‰
        issues.extend(self._check_data_contract(files))
        
        # è§„åˆ™ 17: é˜²å¾¡æ€§ç¼–ç¨‹æ£€æŸ¥ï¼ˆé˜²æ­¢ç¼ºå°‘ç©ºå€¼æ£€æŸ¥ï¼‰
        issues.extend(self._check_defensive_programming(files))
        
        # è·³è¿‡ CSS :global å’Œæœªå¼•ç”¨æ–‡ä»¶æ£€æŸ¥ï¼ˆå·²ç”± Gate3/Gate6 æ£€æŸ¥ï¼‰
        # css_files = {f: c for f, c in files.items() if f.endswith('.module.css')}
        # for filename, content in css_files.items():
        #     issues.extend(self._check_css_module_global_usage(filename, content))
        # issues.extend(self._check_unreferenced_generated_files(files))
        
        # åªæœ‰ ERROR çº§åˆ«çš„ issue æ‰ç®—å¤±è´¥ï¼ŒWARNING ä¸å½±å“é€šè¿‡
        errors = [issue for issue in issues if issue.get('severity') == 'error']
        passed = len(errors) == 0
        
        return GateResult("L0_static", passed, issues)
    
    def _check_controlled_input_missing_onchange(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥å—æ§è¾“å…¥æ˜¯å¦ç¼ºå°‘ onChange"""
        issues = []
        
        # æ›´ç²¾ç¡®çš„æ£€æŸ¥ï¼šæŸ¥æ‰¾ <input æˆ– <Input æ ‡ç­¾ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ value ä½†ç¼ºå°‘ onChange
        # ä½¿ç”¨æ›´ç®€å•çš„æ–¹æ³•ï¼šé€è¡Œæ£€æŸ¥ï¼Œè€Œä¸æ˜¯å¤æ‚çš„æ­£åˆ™
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            line_stripped = line.strip()
            
            # è·³è¿‡æ³¨é‡Šè¡Œ
            if line_stripped.startswith('//') or line_stripped.startswith('/*'):
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ <input æˆ– <Input æ ‡ç­¾ä¸”æœ‰ value å±æ€§
            if ('<input' in line_stripped.lower() or '<Input' in line_stripped) and 'value=' in line_stripped:
                # æ£€æŸ¥æ˜¯å¦æœ‰ onChange æˆ– readOnlyï¼ˆå¯èƒ½åœ¨åŒä¸€è¡Œæˆ–é™„è¿‘å‡ è¡Œï¼‰
                context_start = max(0, i - 2)
                context_end = min(len(lines), i + 3)
                context = '\n'.join(lines[context_start:context_end])
                
                has_onchange = 'onChange' in context or 'onInput' in context
                has_readonly = 'readOnly' in context or 'disabled' in context
                
                if not has_onchange and not has_readonly:
                    issues.append({
                        "rule_id": "controlled_input_missing_onchange",
                        "severity": "error",
                        "file": filename,
                        "line": i + 1,
                        "message": "å—æ§è¾“å…¥ value= ç¼ºå°‘ onChange ä¸”é readOnly",
                        "snippet": line_stripped[:100]
                    })
        
        return issues
    
    def _check_readonly_wrong_condition(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥ readOnly é”å®šæ¡ä»¶æ˜¯å¦æ­£ç¡®"""
        issues = []
        
        # æ£€æµ‹ readOnly={cell ...} ä½†ç¼ºå°‘ original å…³é”®è¯çš„æƒ…å†µ
        pattern = r'readOnly\s*=\s*\{[^}]*\bcell\b(?!.*\boriginal\b)[^}]*\}'
        
        matches = re.finditer(pattern, content, re.IGNORECASE)
        for match in matches:
            line_no = content[:match.start()].count('\n') + 1
            issues.append({
                "rule_id": "readonly_wrong_condition",
                "severity": "warning",
                "file": filename,
                "line": line_no,
                "message": "readOnly é”å®šæ¡ä»¶å¯èƒ½é”™è¯¯ï¼šç”¨å½“å‰ cell è€Œé original",
                "snippet": match.group(0),
                "suggestion": "åº”ä½¿ç”¨ originalBoard æˆ–ç±»ä¼¼çš„åˆå§‹çŠ¶æ€æ¥é”å®š"
            })
        
        return issues
    
    def _check_onclick_no_state_update(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥ onClick handler å†…æ˜¯å¦æœ‰çŠ¶æ€æ›´æ–°"""
        issues = []
        
        # ç®€åŒ–æ£€æµ‹ï¼šåªæ£€æŸ¥æ˜æ˜¾çš„ç©º handler
        # åŒ¹é… onClick={() => {}} æˆ– onClick={handleXXX} è¿™ç§è°ƒç”¨å‡½æ•°çš„æƒ…å†µè·³è¿‡
        
        lines = content.split('\n')
        for i, line in enumerate(lines):
            if 'onClick' in line:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç©º handler
                if 'onClick={}' in line.replace(' ', '') or 'onClick={()=>{}}' in line.replace(' ', ''):
                    issues.append({
                        "rule_id": "onclick_no_state_update",
                        "severity": "warning",
                        "file": filename,
                        "line": i + 1,
                        "message": "onClick handler ä¸ºç©º",
                        "snippet": line.strip()[:100]
                    })
        
        return issues
    
    def _check_empty_handler(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """
        æ£€æŸ¥æ˜¯å¦æœ‰æœªå®ç°çš„äº‹ä»¶å¤„ç†å™¨
        
        é‡‡ç”¨ä¸¤é˜¶æ®µæ£€æµ‹ç­–ç•¥ï¼š
        1. å…ˆç”¨æ­£åˆ™æ‰¾å‡ºæ‰€æœ‰äº‹ä»¶å¤„ç†å™¨
        2. å†ç”¨å¯å‘å¼è§„åˆ™åˆ¤æ–­æ˜¯å¦å·²å®ç°ï¼ˆåŒ…å«å‡½æ•°è°ƒç”¨ã€çŠ¶æ€æ›´æ–°ã€èµ‹å€¼ç­‰ï¼‰
        
        è¿™æ ·å¯ä»¥é¿å…è¯¯æŠ¥ï¼ˆå¦‚ todo å˜é‡åè¢«å½“ä½œ TODO æ³¨é‡Šï¼‰
        """
        issues = []
        
        # é˜¶æ®µ 1: æ‰¾å‡ºæ‰€æœ‰å•è¡Œçš„äº‹ä»¶å¤„ç†å™¨ï¼ˆä¸è·¨è¡Œçš„ç®€å•æƒ…å†µï¼‰
        # åŒ¹é… on[Event]={...} å½¢å¼ï¼Œæ•è·èŠ±æ‹¬å·å†…çš„å†…å®¹
        handler_pattern = r'(on[A-Z]\w*)\s*=\s*\{([^{}]*(?:\{[^{}]*\}[^{}]*)*)\}'
        
        matches = re.finditer(handler_pattern, content)
        for match in matches:
            event_name = match.group(1)  # å¦‚ onClick
            handler_body = match.group(2)  # èŠ±æ‹¬å·å†…çš„å†…å®¹
            
            # é˜¶æ®µ 2: å¯å‘å¼åˆ¤æ–­æ˜¯å¦å·²å®ç°
            is_implemented = self._is_handler_implemented(handler_body)
            
            if not is_implemented:
                line_no = content[:match.start()].count('\n') + 1
                snippet = match.group(0)
                if len(snippet) > 60:
                    snippet = snippet[:57] + "..."
                
                    issues.append({
                        "rule_id": "empty_handler",
                        "severity": "error",
                        "priority": 2,
                        "file": filename,
                    "line": line_no,
                    "message": f"äº‹ä»¶å¤„ç†å™¨ {event_name} æœªå®ç°æˆ–ä¸ºç©º",
                    "snippet": snippet
                })
        
        return issues
    
    def _is_handler_implemented(self, handler_body: str) -> bool:
        """
        å¯å‘å¼åˆ¤æ–­äº‹ä»¶å¤„ç†å™¨æ˜¯å¦å·²å®ç°
        
        åˆ¤æ–­æ ‡å‡†ï¼ˆæ»¡è¶³ä»»ä¸€å³è®¤ä¸ºå·²å®ç°ï¼‰ï¼š
        0. å‡½æ•°å¼•ç”¨ä¼ é€’ï¼šhandleSubmitã€onChange ç­‰ï¼ˆå¸¸è§çš„ React æ¨¡å¼ï¼‰
        1. åŒ…å«å‡½æ•°è°ƒç”¨ï¼šhandle*()ã€set*()ã€*() ç­‰
        2. åŒ…å«å¯¹è±¡æ–¹æ³•è°ƒç”¨ï¼šobj.method()
        3. åŒ…å«èµ‹å€¼æ“ä½œï¼š= 
        4. åŒ…å« return è¯­å¥
        5. é•¿åº¦è¶…è¿‡é˜ˆå€¼ï¼ˆè¯´æ˜æœ‰å®é™…ä»£ç ï¼‰
        
        ä¸ç®—å®ç°çš„æƒ…å†µï¼š
        1. ç©ºå­—ç¬¦ä¸²æˆ–åªæœ‰ç©ºç™½
        2. åªæœ‰æ³¨é‡Š
        3. åªæœ‰ console.log
        """
        # å»é™¤æ³¨é‡Šå’Œç©ºç™½åçš„å†…å®¹
        body_cleaned = re.sub(r'/\*.*?\*/', '', handler_body, flags=re.DOTALL)  # ç§»é™¤å¤šè¡Œæ³¨é‡Š
        body_cleaned = re.sub(r'//.*?$', '', body_cleaned, flags=re.MULTILINE)  # ç§»é™¤å•è¡Œæ³¨é‡Š
        body_cleaned = body_cleaned.strip()
        
        # 1. å®Œå…¨ç©ºæˆ–åªæœ‰ç©ºç™½
        if not body_cleaned:
            return False
        
        # 2. åªæœ‰ç©ºçš„ç®­å¤´å‡½æ•° () => {} æˆ– (e) => {}
        if re.match(r'^\([^)]*\)\s*=>\s*\{\s*\}$', body_cleaned):
            return False
        
        # 3. åªåŒ…å« console.logï¼ˆå ä½ç¬¦ï¼‰
        if 'console.log' in body_cleaned and len(body_cleaned.replace('console.log', '').strip('();, ')) < 10:
            return False
        
        # ğŸ†• 4. æ£€æŸ¥æ˜¯å¦æ˜¯å‡½æ•°å¼•ç”¨ä¼ é€’ï¼ˆå¸¸è§çš„ React æ¨¡å¼ï¼‰
        # ä¾‹å¦‚: handleSubmit, onChange, props.onSave
        if re.match(r'^[a-zA-Z_$][\w$]*(\.[a-zA-Z_$][\w$]*)*$', body_cleaned):
            # å•ä¸ªæ ‡è¯†ç¬¦æˆ–å±æ€§è®¿é—®ï¼ˆå¦‚ handleSubmit æˆ– props.onSaveï¼‰
            # è®¤ä¸ºè¿™æ˜¯ä¼ é€’å‡½æ•°å¼•ç”¨ï¼Œåº”è¯¥æ˜¯å·²å®ç°çš„
            return True
        
        # 5. æ£€æŸ¥æ˜¯å¦åŒ…å«å®é™…å®ç°çš„æ ‡å¿—
        implementation_indicators = [
            r'\w+\(',                    # å‡½æ•°è°ƒç”¨ foo()
            r'\.\w+\(',                  # æ–¹æ³•è°ƒç”¨ obj.method()
            r'set[A-Z]\w*\(',           # setState ç±»è°ƒç”¨
            r'handle\w*\(',             # handle* å‡½æ•°è°ƒç”¨
            r'\w+\s*=\s*\w+',           # èµ‹å€¼æ“ä½œï¼ˆæ’é™¤ç®­å¤´å‡½æ•°çš„ =>ï¼‰
            r'return\s+',               # return è¯­å¥
            r'throw\s+',                # throw è¯­å¥
            r'if\s*\(',                 # æ¡ä»¶è¯­å¥
            r'for\s*\(',                # å¾ªç¯è¯­å¥
            r'while\s*\(',              # å¾ªç¯è¯­å¥
            r'switch\s*\(',             # switch è¯­å¥
        ]
        
        for indicator in implementation_indicators:
            if re.search(indicator, body_cleaned):
                return True
        
        # 6. å¦‚æœæ¸…ç†åçš„ä»£ç è¿˜æœ‰ä¸€å®šé•¿åº¦ï¼Œè®¤ä¸ºå¯èƒ½æœ‰å®ç°ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        if len(body_cleaned) > 20:
            return True
        
        return False
    
    def _check_no_state_management(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥æ˜¯å¦ç¼ºå°‘çŠ¶æ€ç®¡ç†ï¼ˆå¦‚æœå£°ç§°å¯äº¤äº’ï¼‰"""
        issues = []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰äº¤äº’ç›¸å…³çš„å…³é”®è¯
        has_interactive_intent = any(keyword in content.lower() for keyword in [
            'interactive', 'click', 'input', 'form', 'button', 'game', 'todo'
        ])
        
        # æ£€æŸ¥æ˜¯å¦æœ‰çŠ¶æ€ç®¡ç†
        has_state = 'useState' in content or 'useReducer' in content
        
        if has_interactive_intent and not has_state:
            issues.append({
                "rule_id": "no_state_management",
                "severity": "warning",
                "file": filename,
                "line": 1,
                "message": "æ–‡ä»¶çœ‹èµ·æ¥éœ€è¦äº¤äº’ï¼Œä½†ç¼ºå°‘çŠ¶æ€ç®¡ç†ï¼ˆuseState/useReducerï¼‰",
                "snippet": f"æ–‡ä»¶å«æœ‰äº¤äº’å…³é”®è¯ä½†æ— çŠ¶æ€ç®¡ç†"
            })
        
        return issues
    
    def _check_import_boundary_violation(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥å¯¼å…¥è¾¹ç•Œè¿è§„ï¼š../ è·¨è¶Šåˆ°å—ä¿æŠ¤ç›®å½•æˆ–é»‘åå•è·¯å¾„"""
        issues = []
        
        protected_patterns = ['components/ui', 'lib/utils', 'lib/cn']
        
        lines = content.split('\n')
        for i, line in enumerate(lines):
            if 'import' in line and 'from' in line:
                # æå– import è·¯å¾„
                match = re.search(r'from\s+["\']([^"\']+)["\']', line)
                if match:
                    import_path = match.group(1)
                    
                    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç›¸å¯¹è·¯å¾„ç»•è¿‡ï¼ˆ../../ï¼‰
                    if '../' in import_path:
                        # æ£€æŸ¥æ˜¯å¦æŒ‡å‘å—ä¿æŠ¤ç›®å½•
                        for pattern in protected_patterns:
                            if pattern in import_path:
                                issues.append({
                                    "rule_id": "import_boundary_violation",
                                    "severity": "error",
                                    "priority": 1,
                                    "file": filename,
                                    "line": i + 1,
                                    "message": f"å¯¼å…¥è¾¹ç•Œè¿è§„ï¼šä½¿ç”¨ç›¸å¯¹è·¯å¾„ ../ è®¿é—®å—ä¿æŠ¤ç›®å½• {pattern}",
                                    "snippet": line.strip(),
                                    "suggestion": f"åº”ä½¿ç”¨ @/ åˆ«åï¼š@/{pattern}/..."
                                })
        
        return issues
    
    def _check_index_too_large(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥ Index.tsx æ˜¯å¦è¿‡å¤§ï¼Œå»ºè®®æ‹†åˆ†"""
        issues = []
        
        # è·å–é˜ˆå€¼é…ç½®
        threshold = 300  # é»˜è®¤ 300 è¡Œ
        for rule in self.rules:
            if rule.get('id') == 'index_tsx_too_large':
                threshold = rule.get('threshold_lines', 300)
                break
        
        lines = content.split('\n')
        line_count = len(lines)
        
        if line_count > threshold:
            issues.append({
                "rule_id": "index_tsx_too_large",
                "severity": "warning",
                "file": filename,
                "line": 1,
                "message": f"Index.tsx æœ‰ {line_count} è¡Œï¼ˆè¶…è¿‡ {threshold} è¡Œé˜ˆå€¼ï¼‰ï¼Œå»ºè®®æ‹†åˆ†",
                "snippet": f"æ–‡ä»¶è¡Œæ•°: {line_count}",
                "suggestion": "å°†å¤æ‚ç»„ä»¶æ‹†åˆ†åˆ° src/components/generated/<appSlug>/*.tsx"
            })
        
        return issues
    
    def _check_input_text_contrast(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """
        æ£€æŸ¥è¾“å…¥æ¡†æ˜¯å¦æœ‰æ˜ç¡®çš„æ–‡å­—é¢œè‰²ï¼ˆé˜²æ­¢ä¸èƒŒæ™¯è‰²å†²çªï¼‰
        å¸¸è§é—®é¢˜ï¼šæ·±è‰²èƒŒæ™¯ + æ·±è‰²æ–‡å­—ï¼Œæˆ–æµ…è‰²èƒŒæ™¯ + æµ…è‰²æ–‡å­—
        """
        issues = []
        
        # æ£€æµ‹ <input> æˆ– <Input> æ ‡ç­¾
        import re
        
        # åŒ¹é… input æ ‡ç­¾ï¼ˆåŸç”Ÿæˆ– shadcnï¼‰
        # æ”¯æŒå¤šè¡Œå’Œå¤æ‚å±æ€§
        input_pattern = r'<(input|Input)\s+([^/>]*(?:/>|>))'
        inputs = re.finditer(input_pattern, content, re.IGNORECASE | re.DOTALL)
        
        for match in inputs:
            tag_name = match.group(1)
            attributes = match.group(2)
            line_num = content[:match.start()].count('\n') + 1
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„ text-* é¢œè‰²ç±»
            has_text_color = bool(
                re.search(r'\btext-(white|black|gray-\d+|slate-\d+|zinc-\d+|neutral-\d+|stone-\d+)', attributes)
            )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ style ä¸­çš„ color å±æ€§
            has_style_color = bool(
                re.search(r'style=.*?\bcolor\s*:', attributes, re.IGNORECASE)
            )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ className æˆ– classï¼ˆå¯èƒ½åœ¨æ ·å¼æ–‡ä»¶ä¸­å®šä¹‰é¢œè‰²ï¼‰
            has_classname = bool(
                re.search(r'\b(className|class)=', attributes)
            )
            
            # å¦‚æœæ²¡æœ‰ä»»ä½•é¢œè‰²ç›¸å…³çš„æ ·å¼ï¼Œå‘å‡ºè­¦å‘Š
            if not has_text_color and not has_style_color:
                # è·å–æ ‡ç­¾ç‰‡æ®µç”¨äºå±•ç¤º
                tag_snippet = match.group(0)[:100]
                if len(match.group(0)) > 100:
                    tag_snippet += '...'
                
                issues.append({
                    'rule_id': 'input_missing_text_color',
                    'severity': 'warning',  # warning è€Œé errorï¼Œå› ä¸ºé¢œè‰²å¯èƒ½åœ¨å¤–å±‚å®¹å™¨
                    'priority': 3,
                    'file': filename,
                    'line': line_num,
                    'message': f'Input element may lack explicit text color styling (line {line_num}). Text may be invisible against background.',
                    'snippet': tag_snippet,
                    'suggestion': 'Add Tailwind classes: `text-gray-900` (light bg) or `text-white` (dark bg) and `placeholder:text-gray-400` or `placeholder:text-gray-500`'
                })
        
        return issues
    
    def _check_missing_text_color(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """
        æ£€æŸ¥æ–‡æœ¬å…ƒç´ æ˜¯å¦æ˜¾å¼æŒ‡å®šäº†é¢œè‰²ï¼ˆé˜²æ­¢ä¾èµ–å…¨å±€ç»§æ‰¿å¯¼è‡´å¯¹æ¯”åº¦ä¸è¶³ï¼‰
        æ£€æŸ¥ h1-h6, p ç­‰æ–‡æœ¬å…ƒç´ 
        """
        issues = []
        
        # æ£€æµ‹æ ‡é¢˜å…ƒç´  h1-h6
        heading_pattern = r'<(h[1-6])([^>]*)>(.*?)</\1>'
        headings = re.finditer(heading_pattern, content, re.IGNORECASE | re.DOTALL)
        
        for match in headings:
            tag = match.group(1)
            attributes = match.group(2)
            line_num = content[:match.start()].count('\n') + 1
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾å¼çš„ text-* é¢œè‰²ç±»
            has_text_color = bool(
                re.search(r'\btext-(white|black|gray-\d+|slate-\d+|zinc-\d+|neutral-\d+)', attributes)
            )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ style ä¸­çš„ color å±æ€§
            has_style_color = bool(
                re.search(r'style=.*?\bcolor\s*:', attributes, re.IGNORECASE)
            )
            
            if not has_text_color and not has_style_color:
                # è·å–æ ‡ç­¾ç‰‡æ®µç”¨äºå±•ç¤º
                tag_snippet = match.group(0)[:100]
                if len(match.group(0)) > 100:
                    tag_snippet += '...'
                
                issues.append({
                    'rule_id': 'missing_explicit_text_color',
                    'severity': 'warning',  # ä½¿ç”¨ warning è€Œé errorï¼Œé¿å…è¿‡åº¦ä¸¥æ ¼
                    'priority': 3,
                    'file': filename,
                    'line': line_num,
                    'message': f'{tag.upper()} element missing explicit text color (line {line_num}). Text may be invisible against background.',
                    'snippet': tag_snippet,
                    'suggestion': 'Add text-white for dark backgrounds or text-gray-900 for light backgrounds to ensure readability'
                })
        
        return issues
    
    def _check_text_contrast_issues(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """
        æ£€æµ‹æ˜æ˜¾çš„å¯¹æ¯”åº¦é—®é¢˜ï¼ˆå¦‚æ·±è‰²æ–‡å­—åœ¨æ·±è‰²èƒŒæ™¯ä¸Šï¼Œæµ…è‰²æ–‡å­—åœ¨æµ…è‰²èƒŒæ™¯ä¸Šï¼‰
        è¿™ä¸ªæ–¹æ³•æ£€æµ‹åŒä¸€è¡Œä¸­å‡ºç°çš„å±é™©é¢œè‰²ç»„åˆ
        """
        issues = []
        
        # å®šä¹‰å±é™©çš„é¢œè‰²ç»„åˆ
        dark_bg_patterns = [
            'bg-slate-900', 'bg-gray-900', 'bg-zinc-900', 'bg-neutral-900',
            'bg-black', 'bg-card'  # Cyberpunk/Minimal ä¸­ bg-card æ˜¯æ·±è‰²
        ]
        dark_text_patterns = [
            'text-gray-900', 'text-slate-900', 'text-zinc-900', 
            'text-neutral-900', 'text-black'
        ]
        
        light_bg_patterns = [
            'bg-white', 'bg-gray-50', 'bg-gray-100', 'bg-slate-50', 
            'bg-slate-100', 'bg-background'  # æŸäº›æ¨¡æ¿ä¸­ bg-background æ˜¯æµ…è‰²
        ]
        light_text_patterns = [
            'text-white', 'text-gray-50', 'text-gray-100', 
            'text-slate-50', 'text-slate-100'
        ]
        
        lines = content.split('\n')
        for i, line in enumerate(lines):
            # æ£€æŸ¥æ·±è‰²èƒŒæ™¯ + æ·±è‰²æ–‡å­—
            has_dark_bg = any(bg in line for bg in dark_bg_patterns)
            has_dark_text = any(txt in line for txt in dark_text_patterns)
            
            if has_dark_bg and has_dark_text:
                # æ‰¾åˆ°å…·ä½“çš„èƒŒæ™¯å’Œæ–‡å­—ç±»
                found_bg = next((bg for bg in dark_bg_patterns if bg in line), 'dark background')
                found_text = next((txt for txt in dark_text_patterns if txt in line), 'dark text')
                
                issues.append({
                    'rule_id': 'low_contrast_dark_on_dark',
                    'severity': 'error',
                    'priority': 3,
                    'file': filename,
                    'line': i + 1,
                    'message': f'ä½å¯¹æ¯”åº¦ï¼šæ·±è‰²æ–‡å­—({found_text})åœ¨æ·±è‰²èƒŒæ™¯({found_bg})ä¸Šï¼Œæ–‡å­—ä¸å¯è¯»',
                    'snippet': line.strip()[:120],
                    'suggestion': f'å°† {found_text} æ”¹ä¸º text-white æˆ– text-gray-100'
                })
            
            # æ£€æŸ¥æµ…è‰²èƒŒæ™¯ + æµ…è‰²æ–‡å­—
            has_light_bg = any(bg in line for bg in light_bg_patterns)
            has_light_text = any(txt in line for txt in light_text_patterns)
            
            if has_light_bg and has_light_text:
                found_bg = next((bg for bg in light_bg_patterns if bg in line), 'light background')
                found_text = next((txt for txt in light_text_patterns if txt in line), 'light text')
                
                issues.append({
                    'rule_id': 'low_contrast_light_on_light',
                    'severity': 'error',
                    'priority': 3,
                    'file': filename,
                    'line': i + 1,
                    'message': f'ä½å¯¹æ¯”åº¦ï¼šæµ…è‰²æ–‡å­—({found_text})åœ¨æµ…è‰²èƒŒæ™¯({found_bg})ä¸Šï¼Œæ–‡å­—ä¸å¯è¯»',
                    'snippet': line.strip()[:120],
                    'suggestion': f'å°† {found_text} æ”¹ä¸º text-gray-900 æˆ– text-slate-900'
            })
        
        return issues
    
    def _check_css_module_global_usage(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """æ£€æŸ¥ CSS Module æ˜¯å¦ä½¿ç”¨ :global() æ±¡æŸ“å…¨å±€"""
        issues = []
        
        if ':global' in content:
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if ':global' in line:
                    issues.append({
                        "rule_id": "css_module_global_usage",
                        "severity": "error",
                        "file": filename,
                        "line": i + 1,
                        "message": "CSS Module ä½¿ç”¨äº† :global() æ±¡æŸ“å…¨å±€æ ·å¼",
                        "snippet": line.strip()[:100],
                        "suggestion": "ç§»é™¤ :global()ï¼Œä½¿ç”¨å±€éƒ¨æ ·å¼æˆ–é€šè¿‡è®¾è®¡ç³»ç»Ÿçš„å…¨å±€ token"
                    })
        
        return issues
    
    def _check_api_usage_errors(self, filename: str, content: str) -> List[Dict[str, Any]]:
        """
        æ£€æµ‹å¸¸è§çš„åº“ API ä½¿ç”¨é”™è¯¯ï¼ˆé˜²æ­¢æ··æ·†ä¸åŒåº“çš„ APIï¼‰
        
        å¸¸è§é—®é¢˜ï¼š
        - date-fns vs moment.js API æ··æ·†
        - recharts vs Chart.js API æ··æ·†
        - axios vs fetch API æ··æ·†
        """
        issues = []
        
        # æ£€æµ‹æ–‡ä»¶ä¸­å¯¼å…¥çš„åº“
        imports = set()
        import_matches = re.finditer(r'from ["\']([^"\']+)["\']', content)
        for match in import_matches:
            imports.add(match.group(1))
        
        # å®šä¹‰åº“ API é”™è¯¯æ¨¡å¼ï¼š{åº“å: [(é”™è¯¯æ­£åˆ™, é”™è¯¯è¯´æ˜, æ­£ç¡®ç”¨æ³•)]}
        api_error_patterns = {
            'date-fns': [
                (
                    r'\.from\s*\(',
                    'date-fns æ²¡æœ‰ .from() æ–¹æ³•ï¼ˆè¿™æ˜¯ moment.js çš„ APIï¼‰',
                    'ä½¿ç”¨ format(date, pattern), subDays(date, n), addDays(date, n)'
                ),
                (
                    r'\.format\s*\(',
                    'date-fns æ²¡æœ‰ .format() æ–¹æ³•ï¼ˆè¿™æ˜¯ moment.js çš„ APIï¼‰',
                    'ä½¿ç”¨ format(date, pattern) å‡½æ•°'
                ),
                (
                    r'\bmoment\s*\(',
                    'moment.js æœªå®‰è£…ï¼Œåº”ä½¿ç”¨ date-fns',
                    'ä½¿ç”¨ parseISO(string) æˆ– new Date()'
                ),
            ],
            'recharts': [
                (
                    r'Chart\.(Line|Bar|Pie|Area)',
                    'recharts ä¸ä½¿ç”¨ Chart.Line() è¯­æ³•ï¼ˆè¿™æ˜¯ Chart.js çš„ APIï¼‰',
                    'ä½¿ç”¨ JSX ç»„ä»¶: <LineChart>, <BarChart>, <PieChart>'
                ),
                (
                    r'new\s+Chart\s*\(',
                    'recharts æ˜¯å£°æ˜å¼çš„ï¼Œä¸ä½¿ç”¨ new Chart()ï¼ˆè¿™æ˜¯ Chart.js çš„ APIï¼‰',
                    'ä½¿ç”¨ JSX ç»„ä»¶: <LineChart data={...}>'
                ),
            ],
            'axios': [
                (
                    r'axios\.[a-z]+\([^)]*\)\.then\([^)]*\.json\(\)',
                    'axios è¿”å›çš„æ•°æ®å·²ç»æ˜¯ JSONï¼Œä¸éœ€è¦è°ƒç”¨ .json()ï¼ˆè¿™æ˜¯ fetch çš„ APIï¼‰',
                    'ç›´æ¥ä½¿ç”¨ response.data'
                ),
                (
                    r'const\s+data\s*=\s*await\s+response\.json\(\)',
                    'axios çš„å“åº”å·²ç»æ˜¯ JSONï¼Œä¸éœ€è¦ .json()ï¼ˆè¿™æ˜¯ fetch çš„ APIï¼‰',
                    'ä½¿ç”¨ response.data ç›´æ¥è®¿é—®æ•°æ®'
                ),
            ],
            'react-hook-form': [
                (
                    r'<Field\s+',
                    'react-hook-form ä¸ä½¿ç”¨ <Field> ç»„ä»¶ï¼ˆè¿™æ˜¯ Formik çš„ APIï¼‰',
                    'ä½¿ç”¨ <input {...register("fieldName")} />'
                ),
                (
                    r'<Formik\s+',
                    'Formik æœªå®‰è£…ï¼Œåº”ä½¿ç”¨ react-hook-form',
                    'ä½¿ç”¨ useForm() hook'
                ),
            ],
        }
        
        # å¯¹æ¯ä¸ªå¯¼å…¥çš„åº“ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ API ä½¿ç”¨é”™è¯¯
        for lib in imports:
            if lib in api_error_patterns:
                for pattern, error_msg, correct_usage in api_error_patterns[lib]:
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        line_no = content[:match.start()].count('\n') + 1
                        snippet = match.group(0)
                        if len(snippet) > 50:
                            snippet = snippet[:47] + '...'
                        
                        issues.append({
                            'rule_id': 'api_usage_error',
                            'severity': 'error',
                            'priority': 2,
                            'file': filename,
                            'line': line_no,
                            'message': f'[{lib}] {error_msg}',
                            'snippet': snippet,
                            'suggestion': f'æ­£ç¡®ç”¨æ³•: {correct_usage}'
                        })
        
        return issues
    
    def _check_import_export_consistency(self, files: Dict[str, str]) -> List[Dict[str, Any]]:
        """
        æ£€æŸ¥å¯¼å…¥å’Œå¯¼å‡ºçš„ä¸€è‡´æ€§ï¼ˆé˜²æ­¢å¯¼å…¥ä¸å­˜åœ¨çš„å¯¼å‡ºï¼‰
        
        å¸¸è§é—®é¢˜ï¼š
        - Index.tsx å¯¼å…¥ computeOrderStatsï¼Œä½† dashboard-orders.ts å¯¼å‡ºçš„æ˜¯ getOrderStats
        - ç»„ä»¶å¯¼å…¥ FILTER_OPTIONSï¼Œä½†é€»è¾‘æ–‡ä»¶å¿˜è®°å¯¼å‡º
        - è‡ªæ„ˆä¿®æ”¹äº† generated æ–‡ä»¶çš„å¯¼å‡ºï¼Œä½†æ²¡æœ‰åŒæ­¥ä¿®æ”¹å¯¼å…¥
        """
        issues = []
        
        # 1. è§£ææ‰€æœ‰æ–‡ä»¶çš„å¯¼å‡º
        exports_map = {}  # {filepath: set(exported_names)}
        for filename, content in files.items():
            if filename.endswith(('.tsx', '.ts', '.jsx', '.js')):
                exports = self._extract_exports(content)
                if exports:
                    exports_map[filename] = exports
        
        # 2. æ£€æŸ¥æ‰€æœ‰ä¸šåŠ¡ä»£ç æ–‡ä»¶çš„å¯¼å…¥ï¼ˆIndex.tsx å’Œ generated ç»„ä»¶ï¼‰
        files_to_check = []
        
        # æ·»åŠ  Index.tsx
        if 'src/pages/Index.tsx' in files:
            files_to_check.append('src/pages/Index.tsx')
        
        # æ·»åŠ æ‰€æœ‰ generated ç›®å½•ä¸‹çš„ç»„ä»¶
        for filename in files.keys():
            if '/generated/' in filename and filename.endswith(('.tsx', '.jsx', '.ts')):
                files_to_check.append(filename)
        
        # æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶çš„å¯¼å…¥
        for file_path in files_to_check:
            file_content = files[file_path]
            imports = self._extract_named_imports_with_source(file_content)
        
        for imported_name, source_path in imports:
            # åªæ£€æŸ¥é¡¹ç›®å†…éƒ¨çš„å¯¼å…¥ï¼ˆ@/ å¼€å¤´ï¼‰
            if not source_path.startswith('@/'):
                continue
            
            # è§£æç›¸å¯¹è·¯å¾„åˆ°å®é™…æ–‡ä»¶è·¯å¾„
            actual_path = self._resolve_import_path(source_path)
            
            if actual_path and actual_path in exports_map:
                exported_names = exports_map[actual_path]
                
                if imported_name not in exported_names:
                    # å°è¯•æ‰¾åˆ°ç›¸ä¼¼çš„å¯¼å‡ºåï¼ˆå¯èƒ½æ˜¯å‘½åä¸ä¸€è‡´ï¼‰
                    similar = self._find_similar_export(imported_name, exported_names)
                    
                    if similar:
                        suggestion = f"'{actual_path}' å¯¼å‡ºçš„æ˜¯ '{similar}'ï¼Œè¯·åœ¨ {actual_path} ä¸­å°† '{similar}' æ”¹åä¸º '{imported_name}'ï¼Œæˆ–æ·»åŠ åˆ«åï¼šexport {{ {similar} as {imported_name} }}"
                    else:
                            suggestion = f"'{actual_path}' æ²¡æœ‰å¯¼å‡º '{imported_name}'ï¼Œè¯·åœ¨ {actual_path} ä¸­æ·»åŠ ï¼šexport {{ {imported_name} }}"
                    
                    issues.append({
                        'rule_id': 'import_export_mismatch',
                        'severity': 'error',
                        'priority': 1,
                            'file': file_path,
                            'line': self._find_import_line(file_content, imported_name),
                        'message': f"å¯¼å…¥çš„ '{imported_name}' åœ¨ '{actual_path}' ä¸­ä¸å­˜åœ¨",
                        'snippet': f'import {{ {imported_name} }} from "{source_path}"',
                            'suggestion': suggestion,
                            'gate': 'L0_static'
                    })
        
        return issues
    
    def _extract_exports(self, content: str) -> set:
        """æå–æ–‡ä»¶ä¸­æ‰€æœ‰çš„å¯¼å‡ºåç§°"""
        exports = set()
        
        # export function/const/let/var name
        pattern1 = r'export\s+(?:function|const|let|var|async\s+function)\s+(\w+)'
        exports.update(re.findall(pattern1, content))
        
        # export { name1, name2 }
        pattern2 = r'export\s+\{([^}]+)\}'
        for match in re.finditer(pattern2, content):
            names_str = match.group(1)
            for name in names_str.split(','):
                name = name.strip()
                # å¤„ç† as é‡å‘½å
                if ' as ' in name:
                    name = name.split(' as ')[1].strip()
                exports.add(name)
        
        # export type/interface
        pattern3 = r'export\s+(?:type|interface)\s+(\w+)'
        exports.update(re.findall(pattern3, content))
        
        return exports
    
    def _extract_named_imports_with_source(self, content: str) -> list:
        """æå–å¯¼å…¥çš„ç¬¦å·åŠå…¶æ¥æº [(imported_name, source_path), ...]"""
        imports = []
        
        # import { name1, name2 } from 'source'
        pattern = r'import\s+\{([^}]+)\}\s+from\s+["\']([^"\']+)["\']'
        for match in re.finditer(pattern, content):
            names_str = match.group(1)
            source = match.group(2)
            
            for name in names_str.split(','):
                name = name.strip()
                # å¤„ç† type å¯¼å…¥ï¼ˆè·³è¿‡ç±»å‹å¯¼å…¥ï¼Œä¸æ£€æŸ¥ï¼‰
                if name.startswith('type '):
                    continue
                # å¤„ç† as é‡å‘½åï¼ˆå–åŸåï¼‰
                if ' as ' in name:
                    name = name.split(' as ')[0].strip()
                if name:  # åªæ·»åŠ éç©ºåç§°
                    imports.append((name, source))
        
        return imports
    
    def _resolve_import_path(self, import_path: str) -> str:
        """è§£æ @/ åˆ«ååˆ°å®é™…æ–‡ä»¶è·¯å¾„"""
        if import_path.startswith('@/'):
            # @/lib/generated/dashboard-orders -> src/lib/generated/dashboard-orders
            base_path = 'src/' + import_path[2:]
            
            # å°è¯•æ·»åŠ å¯èƒ½çš„æ‰©å±•å
            for ext in ['.ts', '.tsx', '.js', '.jsx']:
                if base_path + ext:
                    return base_path + ext
            
            return base_path + '.ts'  # é»˜è®¤è¿”å› .ts
        
        return None
    
    def _find_similar_export(self, imported_name: str, exported_names: set) -> str:
        """æŸ¥æ‰¾ç›¸ä¼¼çš„å¯¼å‡ºåï¼ˆå¯èƒ½åªæ˜¯å‘½åå·®å¼‚ï¼‰"""
        if not imported_name:  # ç©ºåç§°ï¼ˆtype å¯¼å…¥ç­‰ï¼‰
            return None
        
        imported_lower = imported_name.lower()
        best_match = None
        best_score = 0
        
        for exported in exported_names:
            if len(exported) <= 1:  # è·³è¿‡å•å­—ç¬¦å¯¼å‡º
                continue
                
            exported_lower = exported.lower()
            score = 0
            
            # å®Œå…¨åŒ¹é…ï¼ˆä¸åº”è¯¥åˆ°è¿™é‡Œï¼Œä½†ä½œä¸ºä¿é™©ï¼‰
            if imported_lower == exported_lower:
                return exported
            
            # æ£€æŸ¥æ˜¯å¦ä¸€ä¸ªæ˜¯å¦ä¸€ä¸ªçš„å­ä¸²ï¼ˆæ›´é•¿çš„ä¼˜å…ˆï¼‰
            if imported_lower in exported_lower:
                score = len(imported_name) * 2
            elif exported_lower in imported_lower:
                score = len(exported) * 2
            
            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            imported_words = set(re.findall(r'[A-Z][a-z]+|[a-z]+', imported_name))
            exported_words = set(re.findall(r'[A-Z][a-z]+|[a-z]+', exported))
            common_words = imported_words & exported_words
            
            if len(common_words) >= 2:  # è‡³å°‘2ä¸ªç›¸åŒçš„è¯
                score += len(common_words) * 10
            
            # æ›´æ–°æœ€ä½³åŒ¹é…
            if score > best_score:
                best_score = score
                best_match = exported
        
        # åªè¿”å›è¶³å¤Ÿç›¸ä¼¼çš„åŒ¹é…ï¼ˆscore > 15ï¼‰
        return best_match if best_score > 15 else None
    
    def _find_import_line(self, content: str, imported_name: str) -> int:
        """æ‰¾åˆ°å¯¼å…¥è¯­å¥æ‰€åœ¨çš„è¡Œå·"""
        lines = content.split('\n')
        for i, line in enumerate(lines, 1):
            if f'{imported_name}' in line and 'import' in line:
                return i
        return 1
    
    def _check_dependency_consistency(self, files: Dict[str, str]) -> List[Dict[str, Any]]:
        """
        æ£€æŸ¥ä¾èµ–ä¸€è‡´æ€§ï¼šç¡®ä¿ä½¿ç”¨çš„ä¾èµ–éƒ½å·²å£°æ˜åœ¨ vibe.meta.json ä¸­
        
        è¿™æ˜¯ä¸€ä¸ªå…³é”®çš„é—¨ç¦ï¼Œé˜²æ­¢ä¾èµ–æ³¨å…¥å¤±è´¥å¯¼è‡´è¿è¡Œæ—¶é”™è¯¯
        """
        issues = []
        
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰ vibe.meta.json
        if 'vibe.meta.json' not in files:
            issues.append({
                'rule_id': 'missing_vibe_meta',
                'severity': 'error',
                'priority': 2,
                'file': 'vibe.meta.json',
                'line': 1,
                'message': 'vibe.meta.json æ–‡ä»¶ç¼ºå¤±ï¼Œä¾èµ–ä¿¡æ¯æ— æ³•ä¼ é€’ç»™å‰ç«¯',
                'snippet': '',
                'suggestion': 'ç¡®ä¿ç”Ÿæˆæµç¨‹ä¸­åˆ›å»ºäº† vibe.meta.json'
            })
            return issues
        
        # 2. è§£æ vibe.meta.json
        try:
            import json
            vibe_meta = json.loads(files['vibe.meta.json'])
        except Exception as e:
            issues.append({
                'rule_id': 'invalid_vibe_meta',
                'severity': 'error',
                'priority': 2,
                'file': 'vibe.meta.json',
                'line': 1,
                'message': f'vibe.meta.json æ ¼å¼é”™è¯¯: {str(e)}',
                'snippet': '',
                'suggestion': 'æ£€æŸ¥ JSON æ ¼å¼æ˜¯å¦æ­£ç¡®'
            })
            return issues
        
        # 3. æ£€æŸ¥ä¾èµ–å­—æ®µæ˜¯å¦å­˜åœ¨
        if 'dependencies' not in vibe_meta:
            issues.append({
                'rule_id': 'missing_dependencies_field',
                'severity': 'warning',
                'file': 'vibe.meta.json',
                'line': 1,
                'message': 'vibe.meta.json ç¼ºå°‘ dependencies å­—æ®µ',
                'snippet': '',
                'suggestion': 'ç¡®ä¿ä¾èµ–æ£€æµ‹å’Œä»²è£æµç¨‹æ­£å¸¸è¿è¡Œ'
            })
            return issues
        
        dependencies = vibe_meta.get('dependencies', {})
        approved_deps = dependencies.get('approved', {})
        
        # 4. æ£€æµ‹ä»£ç ä¸­å®é™…ä½¿ç”¨çš„ç¬¬ä¸‰æ–¹ä¾èµ–
        from dependency_detector import (
            detect_imports_in_code, 
            PRESET_PACKAGES,
            NODEJS_BUILTIN_MODULES,
            DEV_DEPENDENCIES
        )
        
        # é…ç½®æ–‡ä»¶åˆ—è¡¨ï¼ˆä¸æ£€æµ‹è¿™äº›æ–‡ä»¶ä¸­çš„å¯¼å…¥ï¼‰
        config_file_patterns = ['vite.config', 'tailwind.config', 'postcss.config', 'eslint.config']
        
        all_imports = set()
        for filename, content in files.items():
            # è·³è¿‡é…ç½®æ–‡ä»¶
            if any(pattern in filename for pattern in config_file_patterns):
                continue
                
            if filename.endswith(('.tsx', '.ts', '.jsx', '.js')):
                imports = detect_imports_in_code(content)
                all_imports.update(imports)
        
        # ä¸‰å±‚è¿‡æ»¤ï¼šé¢„è®¾ â†’ Node.js å†…ç½® â†’ å¼€å‘ä¾èµ–
        third_party_imports = all_imports - PRESET_PACKAGES - NODEJS_BUILTIN_MODULES - DEV_DEPENDENCIES
        
        # 5. æ£€æŸ¥æ˜¯å¦æœ‰ä½¿ç”¨ä½†æœªæ‰¹å‡†çš„ä¾èµ–
        unapproved_deps = third_party_imports - set(approved_deps.keys())
        
        if unapproved_deps:
            for pkg in sorted(unapproved_deps):
                issues.append({
                    'rule_id': 'unapproved_dependency_used',
                    'severity': 'error',
                    'priority': 2,
                    'file': 'vibe.meta.json',
                    'line': 1,
                    'message': f'ä»£ç ä¸­ä½¿ç”¨äº†æœªæ‰¹å‡†çš„ä¾èµ–: {pkg}',
                    'snippet': f'import ... from "{pkg}"',
                    'suggestion': f'ä¾èµ– {pkg} éœ€è¦æ·»åŠ åˆ°ç™½åå•æˆ–ä»ä»£ç ä¸­ç§»é™¤'
                })
        
        # 6. æ£€æŸ¥æ˜¯å¦æœ‰æ‰¹å‡†ä½†æœªä½¿ç”¨çš„ä¾èµ–ï¼ˆè­¦å‘Šï¼Œä¸æ˜¯é”™è¯¯ï¼‰
        unused_deps = set(approved_deps.keys()) - third_party_imports
        
        if unused_deps:
            for pkg in sorted(unused_deps):
                issues.append({
                    'rule_id': 'approved_dependency_unused',
                    'severity': 'warning',
                    'file': 'vibe.meta.json',
                    'line': 1,
                    'message': f'æ‰¹å‡†çš„ä¾èµ–æœªè¢«ä½¿ç”¨: {pkg}',
                    'snippet': f'{pkg}@{approved_deps[pkg]}',
                    'suggestion': 'è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼ˆå¦‚ç±»å‹å®šä¹‰ï¼‰ï¼Œæˆ–è€…æ˜¯è¯¯æ£€æµ‹'
                })
        
        return issues
    
    def _check_export_consistency(self, files: Dict[str, str]) -> List[Dict[str, Any]]:
        """
        æ£€æŸ¥å¯¼å‡ºä¸€è‡´æ€§é—®é¢˜
        
        è§„åˆ™ï¼š
        1. Index.tsx å¿…é¡»ä½¿ç”¨é»˜è®¤å¯¼å‡º: export default function Index()
        2. å…¶ä»–ç»„ä»¶åº”ä½¿ç”¨å‘½åå¯¼å‡ºï¼Œä¸”å¯¼å‡ºååº”ä¸æ–‡ä»¶ååŒ¹é…
        3. æ£€æµ‹å¯¼å…¥/å¯¼å‡ºä¸åŒ¹é…çš„æƒ…å†µ
        """
        issues = []
        
        for filename, content in files.items():
            if not filename.endswith(('.tsx', '.jsx', '.ts', '.js')):
                continue
            
            # è§„åˆ™ 1: Index.tsx å¿…é¡»ä½¿ç”¨é»˜è®¤å¯¼å‡º
            if 'Index.tsx' in filename or 'Index.jsx' in filename:
                has_default_export = bool(re.search(r'export\s+default\s+', content))
                has_named_export = bool(re.search(r'export\s+(const|function|class)\s+Index\b', content))
                
                if not has_default_export:
                    issues.append({
                        "rule_id": "index_missing_default_export",
                        "severity": "error",
                        "priority": 2,
                        "file": filename,
                        "line": 1,
                        "message": "Index.tsx å¿…é¡»ä½¿ç”¨é»˜è®¤å¯¼å‡º: export default function Index()",
                        "snippet": "ç¼ºå°‘ export default",
                        "suggestion": "ä½¿ç”¨ 'export default function Index()' æˆ– 'export default Index'"
                    })
                
                if has_named_export and not has_default_export:
                    issues.append({
                        "rule_id": "index_wrong_export_type",
                        "severity": "error",
                        "priority": 2,
                        "file": filename,
                        "line": 1,
                        "message": "Index.tsx ä½¿ç”¨äº†å‘½åå¯¼å‡ºè€Œä¸æ˜¯é»˜è®¤å¯¼å‡º",
                        "snippet": "export const Index æˆ– export function Index",
                        "suggestion": "æ”¹ä¸º 'export default function Index()'"
                    })
            
            # è§„åˆ™ 2: æ£€æŸ¥ç»„ä»¶æ–‡ä»¶çš„å¯¼å‡ºåæ˜¯å¦ä¸æ–‡ä»¶ååŒ¹é…
            elif '/components/generated/' in filename and filename.endswith(('.tsx', '.jsx')):
                # æå–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åå’Œè·¯å¾„ï¼‰
                file_basename = filename.split('/')[-1].replace('.tsx', '').replace('.jsx', '')
                
                # å°† kebab-case æˆ– snake_case è½¬æ¢ä¸º PascalCase
                # ä¾‹å¦‚: neon-counter-card -> NeonCounterCard
                component_name_pascal = ''.join(
                    word.capitalize() for word in file_basename.replace('_', '-').split('-')
                )
                
                # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„å‘½åå¯¼å‡ºï¼ˆæ”¯æŒåŸæ–‡ä»¶åå’Œ PascalCase ä¸¤ç§å½¢å¼ï¼‰
                has_matching_export = bool(re.search(
                    rf'export\s+(const|function|class)\s+({re.escape(component_name_pascal)}|{re.escape(file_basename)})\b',
                    content
                ))
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†é»˜è®¤å¯¼å‡ºï¼ˆå¯¹äºç»„ä»¶æ¥è¯´æ˜¯ä¸æ¨èçš„ï¼‰
                has_default_export = bool(re.search(r'export\s+default\s+', content))
                
                if not has_matching_export and not has_default_export:
                    issues.append({
                        "rule_id": "component_missing_export",
                        "severity": "error",
                        "priority": 2,
                        "file": filename,
                        "line": 1,
                        "message": f"ç»„ä»¶æ–‡ä»¶ {file_basename}.tsx ç¼ºå°‘å¯¹åº”çš„å¯¼å‡º",
                        "snippet": f"æœªæ‰¾åˆ° export const {component_name_pascal} æˆ– export default",
                        "suggestion": f"æ·»åŠ  'export const {component_name_pascal} = ...' æˆ– 'export default'"
                    })
                
                # å¦‚æœåªæœ‰é»˜è®¤å¯¼å‡ºï¼Œè­¦å‘Šåº”è¯¥ä½¿ç”¨å‘½åå¯¼å‡º
                if has_default_export and not has_matching_export:
                    issues.append({
                        "rule_id": "component_should_use_named_export",
                        "severity": "warning",
                        "file": filename,
                        "line": 1,
                        "message": f"ç»„ä»¶ {file_basename} ä½¿ç”¨äº†é»˜è®¤å¯¼å‡ºï¼Œå»ºè®®ä½¿ç”¨å‘½åå¯¼å‡º",
                        "snippet": "export default ...",
                        "suggestion": f"æ”¹ä¸º 'export const {component_name_pascal} = ...' ä»¥æé«˜å¯¼å…¥ä¸€è‡´æ€§"
                    })
        
        return issues
    
    def _check_unreferenced_generated_files(self, files: Dict[str, str]) -> List[Dict[str, Any]]:
        """æ£€æŸ¥æœªå¼•ç”¨çš„ generated æ–‡ä»¶"""
        issues = []
        
        # æ‰¾å‡ºæ‰€æœ‰ generated ç›®å½•ä¸­çš„ç»„ä»¶æ–‡ä»¶
        generated_files = [f for f in files.keys() 
                          if '/generated/' in f and f.endswith(('.tsx', '.ts'))]
        
        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶çš„å¯¼å…¥è¯­å¥
        all_imports = []
        for filename, content in files.items():
            if filename.endswith(('.tsx', '.ts', '.jsx', '.js')):
                # æå–æ‰€æœ‰ import è¯­å¥
                import_matches = re.findall(r'from\s+["\']([^"\']+)["\']', content)
                all_imports.extend(import_matches)
        
        # æ£€æŸ¥æ¯ä¸ª generated æ–‡ä»¶æ˜¯å¦è¢«å¼•ç”¨
        for gen_file in generated_files:
            # æå–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            file_base = gen_file.replace('.tsx', '').replace('.ts', '')
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å¯¼å…¥åŒ…å«è¿™ä¸ªæ–‡ä»¶è·¯å¾„
            is_referenced = False
            for imp in all_imports:
                if file_base in imp or gen_file.split('/')[-1].replace('.tsx', '').replace('.ts', '') in imp:
                    is_referenced = True
                    break
            
            if not is_referenced:
                issues.append({
                    "rule_id": "unreferenced_generated_file",
                    "severity": "warning",
                    "file": gen_file,
                    "line": 1,
                    "message": f"ç”Ÿæˆçš„æ–‡ä»¶ {gen_file} æœªè¢«ä»»ä½•å…¶ä»–æ–‡ä»¶å¼•ç”¨",
                    "snippet": "æœªè¢«å¼•ç”¨çš„æ–‡ä»¶",
                    "suggestion": "è¦ä¹ˆåœ¨ Index.tsx æˆ–å…¶ä»–ç»„ä»¶ä¸­å¯¼å…¥å®ƒï¼Œè¦ä¹ˆåˆ é™¤å®ƒ"
            })
        
        return issues
    
    def _check_duplicate_definitions(self, files: Dict[str, str]) -> List[Dict[str, Any]]:
        """æ£€æµ‹åŒä¸€æ–‡ä»¶ä¸­çš„é‡å¤å‡½æ•°/ç±»å®šä¹‰"""
        issues = []
        
        for filename, content in files.items():
            if not filename.endswith(('.ts', '.tsx', '.js', '.jsx')):
                continue
            
            # æå–æ‰€æœ‰ export å®šä¹‰
            export_pattern = r'export\s+(?:function|const|let|var|class)\s+(\w+)'
            exports = re.findall(export_pattern, content)
            
            # æ£€æµ‹é‡å¤
            seen = {}
            for name in exports:
                if name in seen:
                    seen[name] += 1
                else:
                    seen[name] = 1
            
            duplicates = {name: count for name, count in seen.items() if count > 1}
            
            for dup_name, count in duplicates.items():
                # æ‰¾åˆ°æ‰€æœ‰å®šä¹‰çš„è¡Œå·
                lines = content.split('\n')
                locations = []
                for i, line in enumerate(lines, 1):
                    if f'export function {dup_name}' in line or f'export const {dup_name}' in line:
                        locations.append(i)
                
                issues.append({
                    'rule_id': 'duplicate_export_definition',
                    'severity': 'error',
                    'priority': 1,  # æœ€é«˜ä¼˜å…ˆçº§
                    'file': filename,
                    'line': locations[0] if locations else 1,
                    'message': f'å‡½æ•°/å˜é‡ {dup_name} åœ¨åŒä¸€æ–‡ä»¶ä¸­å®šä¹‰äº† {count} æ¬¡ï¼ˆè¡Œå·: {", ".join(map(str, locations))}ï¼‰',
                    'snippet': f'export ... {dup_name}',
                    'suggestion': f'åˆ é™¤é‡å¤çš„ {dup_name} å®šä¹‰ï¼Œåªä¿ç•™æœ€å®Œæ•´çš„ç‰ˆæœ¬'
                })
        
        return issues
    
    def _check_data_contract(self, files: Dict[str, str]) -> List[Dict[str, Any]]:
        """æ£€æµ‹å‡½æ•°è¿”å›å€¼æ˜¯å¦æ»¡è¶³ç»„ä»¶æœŸæœ›"""
        issues = []
        
        # é’ˆå¯¹å¸¸è§æ¨¡å¼ï¼šç›´æ¥æ£€æŸ¥è¿”å›å¯¹è±¡ç¼ºå°‘å­—æ®µ
        for filename, content in files.items():
            if not filename.endswith(('.ts', '.tsx')):
                continue
            
            if '/lib/generated/' not in filename and '/pages/' not in filename:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªreturnè¯­å¥è¿”å›ä¸åŒçš„å­—æ®µ
            return_blocks = re.findall(r'return\s*\{([^}]+)\}', content)
            
            if len(return_blocks) > 1:
                field_sets = []
                for block in return_blocks:
                    fields = {f.strip().split(':')[0].strip() for f in block.split(',') if f.strip()}
                    field_sets.append(fields)
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰returnéƒ½è¿”å›ç›¸åŒçš„å­—æ®µ
                if len(field_sets) >= 2:
                    first_fields = field_sets[0]
                    for i, fields in enumerate(field_sets[1:], 1):
                        missing = first_fields - fields
                        extra = fields - first_fields
                        
                        if missing or extra:
                            issues.append({
                                'rule_id': 'data_contract_violation',
                                'severity': 'error',
                                'priority': 2,
                                'file': filename,
                                'line': 1,
                                'message': f'å‡½æ•°è¿”å›çš„æ•°æ®ç»“æ„ä¸ä¸€è‡´ï¼šç¬¬1ä¸ªreturnæœ‰{first_fields}ï¼Œç¬¬{i+1}ä¸ªreturnç¼ºå°‘{missing}ï¼Œå¤šå‡º{extra}',
                                'snippet': 'return { ... }',
                                'suggestion': f'ç¡®ä¿æ‰€æœ‰returnè¯­å¥è¿”å›ç›¸åŒçš„å­—æ®µé›†åˆ'
                            })
        
        return issues
    
    def _check_defensive_programming(self, files: Dict[str, str]) -> List[Dict[str, Any]]:
        """æ£€æµ‹ç¼ºå°‘ç©ºå€¼æ£€æŸ¥çš„ä»£ç """
        issues = []
        
        # æ’é™¤ä¸åº”æ£€æŸ¥çš„ç›®å½•ï¼ˆUI åº“ç»„ä»¶ã€å·¥å…·å‡½æ•°ç­‰ï¼‰
        excluded_patterns = [
            'src/components/ui/',
            'src/lib/utils',
            'node_modules/',
        ]
        
        dangerous_patterns = [
            (r'(\w+)\.(\w+)\.toLocaleString\(\)', 'toLocaleString()'),
            (r'(\w+)\.(\w+)\.map\(', 'map()'),
            (r'(\w+)\.(\w+)\.length', 'length'),
            (r'(\w+)\.(\w+)\.push\(', 'push()'),
        ]
        
        for filename, content in files.items():
            if not filename.endswith(('.tsx', '.jsx')):
                continue
            
            # è·³è¿‡æ’é™¤çš„ç›®å½•
            if any(pattern in filename for pattern in excluded_patterns):
                continue
            
            lines = content.split('\n')
            
            for pattern, method_name in dangerous_patterns:
                for line_num, line in enumerate(lines, 1):
                    matches = re.finditer(pattern, line)
                    
                    for match in matches:
                        obj = match.group(1)
                        field = match.group(2)
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰å¯é€‰é“¾æˆ–æ¡ä»¶æ£€æŸ¥
                        has_optional_chain = '?.' in line[:match.start()]
                        has_conditional = f'{obj} &&' in line or f'{obj}?' in line
                        
                        if not has_optional_chain and not has_conditional:
                            issues.append({
                                'rule_id': 'missing_null_check',
                                'severity': 'error',
                                'priority': 3,
                                'file': filename,
                                'line': line_num,
                                'message': f'ç¼ºå°‘ç©ºå€¼æ£€æŸ¥ï¼š{obj}.{field}.{method_name} å¯èƒ½åœ¨ {obj}.{field} ä¸º undefined æ—¶å´©æºƒ',
                                'snippet': line.strip(),
                                'suggestion': f'ä½¿ç”¨å¯é€‰é“¾ï¼š{obj}?.{field}?.{method_name} æˆ–æ·»åŠ æ¡ä»¶ï¼š{obj} && {obj}.{field}'
                            })
        
        return issues


def run_quality_gates(files: Dict[str, str]) -> Dict[str, GateResult]:
    """
    è¿è¡Œæ‰€æœ‰å¯ç”¨çš„è´¨é‡é—¨ç¦
    
    Args:
        files: æ–‡ä»¶å­—å…¸
        
    Returns:
        é—¨ç¦ç»“æœå­—å…¸ {level_name: GateResult}
    """
    results = {}
    
    if not policy_manager.is_quality_gates_enabled():
        print("   âš ï¸  è´¨é‡é—¨ç¦æœªå¯ç”¨")
        return results
    
    enabled_levels = policy_manager.get_enabled_gate_levels()
    print(f"   ğŸš¦ è¿è¡Œè´¨é‡é—¨ç¦: {', '.join(enabled_levels)}")
    
    for level_name in enabled_levels:
        if level_name == "L0_static":
            # è¿è¡Œæ—§çš„ L0StaticGateï¼ˆå…¼å®¹æ€§ï¼‰
            old_gate = L0StaticGate()
            old_result = old_gate.check(files)
            
            # è¿è¡Œæ–°çš„ L0 äº¤äº’/æ ·å¼é—¨ç¦ï¼ˆGate1-8ï¼‰
            from l0_gates import run_l0_gates
            context = {'prompt_text': '', 'app_slug': 'unknown'}  # ä»æ–‡ä»¶æ¨æ–­
            new_l0_result = run_l0_gates(files, context)
            
            # è½¬æ¢æ–°æ ¼å¼åˆ°æ—§æ ¼å¼ï¼ˆæ ‡å‡†åŒ–ï¼‰
            new_issues_converted = []
            for fail in new_l0_result.fails:
                new_issues_converted.append({
                    'severity': 'error',
                    'file': fail.get('files', [''])[0] if fail.get('files') else '',
                    'line': fail.get('line', 1),
                    'message': f"[{fail.get('gate', 'UNKNOWN')}] {fail.get('message', '')}",
                    'suggestion': fail.get('suggestion', '')
                })
            for warn in new_l0_result.warnings:
                new_issues_converted.append({
                    'severity': 'warning',
                    'file': warn.get('files', [''])[0] if warn.get('files') else '',
                    'line': warn.get('line', 1),
                    'message': f"[{warn.get('gate', 'UNKNOWN')}] {warn.get('message', '')}",
                    'suggestion': warn.get('suggestion', '')
                })
            
            # åˆå¹¶ä¸¤ä¸ªç»“æœ
            combined_issues = old_result.issues + new_issues_converted
            combined_passed = old_result.passed and new_l0_result.pass_status
            result = GateResult("L0_static", combined_passed, combined_issues)
            results[level_name] = result
            
            if result.passed:
                print(f"   âœ“ {level_name}: é€šè¿‡")
            else:
                errors = [i for i in combined_issues if i.get('severity') == 'error' or i.get('gate')]
                print(f"   âœ— {level_name}: å‘ç° {len(errors)} ä¸ªé—®é¢˜")
                for issue in errors[:3]:  # åªæ˜¾ç¤ºå‰ 3 ä¸ª
                    msg = issue.get('message', '')
                    file = issue.get('file') or (issue.get('files', [''])[0] if issue.get('files') else '')
                    line = issue.get('line', '?')
                    print(f"     - {msg[:80]} ({file}:{line})")
                if len(errors) > 3:
                    print(f"     - ... è¿˜æœ‰ {len(errors) - 3} ä¸ªé—®é¢˜")
        
        # L1, L2, L3 é—¨ç¦éœ€è¦åœ¨ WebContainer å†…è¿è¡Œï¼Œè¿™é‡Œåªåšå ä½
        elif level_name == "L1_typecheck":
            print(f"   â­ï¸  {level_name}: éœ€è¦åœ¨ WebContainer å†…è¿è¡Œï¼ˆæš‚æœªå®ç°ï¼‰")
            results[level_name] = GateResult(level_name, True, [])
        
        elif level_name == "L2_smoke_test":
            print(f"   â­ï¸  {level_name}: éœ€è¦åœ¨ WebContainer å†…è¿è¡Œï¼ˆæš‚æœªå®ç°ï¼‰")
            results[level_name] = GateResult(level_name, True, [])
        
        elif level_name == "L3_lint":
            print(f"   â­ï¸  {level_name}: éœ€è¦åœ¨ WebContainer å†…è¿è¡Œï¼ˆæš‚æœªå®ç°ï¼‰")
            results[level_name] = GateResult(level_name, True, [])
    
    return results


def format_gate_results_for_heal(
    results: Dict[str, GateResult], 
    max_issues: int = 8,
    group_by_file: bool = True
) -> str:
    """
    å°†é—¨ç¦ç»“æœæ ¼å¼åŒ–ä¸ºé€‚åˆè‡ªæ„ˆå¾ªç¯çš„æ–‡æœ¬
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆpriority 1 > 2 > 3ï¼‰
    2. æ™ºèƒ½åˆ†ç»„ï¼ˆåŒæ–‡ä»¶çš„é”™è¯¯åˆå¹¶ï¼‰
    3. é™åˆ¶æ•°é‡ï¼ˆæœ€å¤šæ˜¾ç¤º max_issues ä¸ªæœ€é‡è¦çš„é—®é¢˜ï¼‰
    
    Args:
        results: é—¨ç¦ç»“æœå­—å…¸
        max_issues: æœ€å¤šæ˜¾ç¤ºçš„é—®é¢˜æ•°é‡
        group_by_file: æ˜¯å¦æŒ‰æ–‡ä»¶åˆ†ç»„
        
    Returns:
        æ ¼å¼åŒ–çš„é”™è¯¯æŠ¥å‘Š
    """
    # 1. æ”¶é›†æ‰€æœ‰é”™è¯¯
    all_issues = []
    for level_name, result in results.items():
        if not result.passed:
            for issue in result.issues:
                # åªå¤„ç† ERROR çº§åˆ«ï¼ˆWARNING ä¸é˜»å¡ï¼‰
                if issue.get('severity') == 'error':
                    issue['gate'] = level_name
                    all_issues.append(issue)
    
    if not all_issues:
        return "No errors found."
    
    # 2. æŒ‰ä¼˜å…ˆçº§æ’åº
    def get_priority(issue):
        # ä¼˜å…ˆçº§ï¼špriorityå­—æ®µ > severityæ˜ å°„
        if 'priority' in issue:
            return issue['priority']
        # å…¼å®¹æ—§ä»£ç 
        severity_map = {'critical': 1, 'error': 2, 'warning': 3}
        return severity_map.get(issue.get('severity', 'error'), 2)
    
    all_issues.sort(key=get_priority)
    
    # 3. æ™ºèƒ½åˆ†ç»„ï¼ˆåŒæ–‡ä»¶çš„é”™è¯¯åˆå¹¶ï¼‰
    if group_by_file:
        grouped = {}
        for issue in all_issues:
            file_key = issue.get('file', 'unknown')
            if file_key not in grouped:
                grouped[file_key] = []
            grouped[file_key].append(issue)
        
        # 4. ç”ŸæˆæŠ¥å‘Šï¼ˆé™åˆ¶æ•°é‡ï¼‰
        report_lines = ["QUALITY GATE FAILURES (Prioritized & Grouped):\n"]
        issue_count = 0
        
        for filename, file_issues in grouped.items():
            if issue_count >= max_issues:
                break
            
            report_lines.append(f"\nğŸ“„ {filename}:")
            
            for issue in file_issues[:max_issues - issue_count]:
                priority_icon = {1: 'ğŸ”´', 2: 'ğŸŸ ', 3: 'ğŸŸ¡'}.get(get_priority(issue), 'âšª')
                rule_id = issue.get('rule_id', 'unknown')
                
                report_lines.append(
                    f"  {priority_icon} [{rule_id}] Line {issue.get('line', '?')}: {issue['message']}"
                )
                
                if 'suggestion' in issue and issue['suggestion']:
                    # å»ºè®®æœ€å¤šæ˜¾ç¤º100å­—ç¬¦
                    suggestion = issue['suggestion'][:100]
                    report_lines.append(f"     ğŸ’¡ {suggestion}")
                
                issue_count += 1
                
                if issue_count >= max_issues:
                    break
        
        # 5. æ·»åŠ æ±‡æ€»
        remaining = len(all_issues) - issue_count
        if remaining > 0:
            report_lines.append(f"\n... and {remaining} more issues (fix above first)")
        
        return "\n".join(report_lines)
    
    else:
        # ä¸åˆ†ç»„ï¼Œç›´æ¥æ˜¾ç¤ºå‰Nä¸ª
        report_lines = ["QUALITY GATE FAILURES (Top Priority):\n"]
        
        for i, issue in enumerate(all_issues[:max_issues]):
            priority_icon = {1: 'ğŸ”´', 2: 'ğŸŸ ', 3: 'ğŸŸ¡'}.get(get_priority(issue), 'âšª')
            report_lines.append(
                f"{i+1}. {priority_icon} {issue.get('file', '?')}:{issue.get('line', '?')} - {issue['message']}"
            )
            if 'suggestion' in issue:
                report_lines.append(f"   ğŸ’¡ {issue['suggestion'][:100]}")
        
        remaining = len(all_issues) - max_issues
        if remaining > 0:
            report_lines.append(f"\n... and {remaining} more issues")
        
        return "\n".join(report_lines)

