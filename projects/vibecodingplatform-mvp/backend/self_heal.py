"""
è‡ªæ„ˆå¾ªç¯ - è‡ªåŠ¨ä¿®å¤è´¨é‡é—¨ç¦å¤±è´¥çš„ä»£ç 
"""
import json
import fnmatch
from typing import Dict, Any, Tuple, List
from policies import policy_manager
from quality_gates import run_quality_gates, format_gate_results_for_heal, GateResult
from langchain_core.messages import HumanMessage
from prompt_fragments import (
    build_base_rules,
    build_dynamic_rules,
    format_spec_payload,
    get_policy_version,
    log_prompt_telemetry,
    compute_prompt_hash
)
from dependency_detector import detect_dependencies_in_files
from dependency_arbiter import DependencyArbiter


def build_heal_prompt(
    gate_results: Dict[str, GateResult],
    interaction_spec: Dict[str, Any],
    current_files: Dict[str, str],
    iteration: int
) -> tuple[str, List[str]]:
    """
    æ„å»ºè‡ªæ„ˆä¿®å¤çš„ promptï¼ˆå›ºå®š 5 æ®µæ¨¡æ¿ï¼‰
    
    Args:
        gate_results: é—¨ç¦ç»“æœ
        interaction_spec: InteractionSpec
        current_files: å½“å‰æ–‡ä»¶
        iteration: å½“å‰è¿­ä»£æ¬¡æ•°
        
    Returns:
        (ä¿®å¤ prompt, æ¿€æ´»çš„åŠ¨æ€è§„åˆ™ IDs)
    """
    # === ç¬¬ 1 æ®µ: Goal ===
    goal_section = f"""GOAL: Fix quality gate failures and keep application runnable.
Iteration {iteration + 1}/{policy_manager.get_max_heal_iterations()}"""
    
    # === ç¬¬ 2 æ®µ: FailedGatesï¼ˆçŸ­åˆ—è¡¨ï¼‰===
    failed_gates = []
    for gate_name, result in gate_results.items():
        if not result.passed:
            issue_count = len(result.issues)
            failed_gates.append(f"  - {gate_name}: {issue_count} issues")
    
    failed_gates_section = "FAILED GATES:\n" + "\n".join(failed_gates)
    
    # === ç¬¬ 3 æ®µ: Evidenceï¼ˆé—¨ç¦è¯æ®ï¼Œä¼˜åŒ–åä¸éœ€è¦æˆªæ–­ï¼‰===
    gate_errors = format_gate_results_for_heal(
        gate_results, 
        max_issues=8,  # é™åˆ¶ä¸º8ä¸ªæœ€é‡è¦çš„é—®é¢˜
        group_by_file=True  # æŒ‰æ–‡ä»¶åˆ†ç»„
    )
    
    # ç§»é™¤æ—§çš„æˆªæ–­é€»è¾‘ï¼ˆæ–°æ–¹æ³•å·²å†…ç½®æ™ºèƒ½é™åˆ¶ï¼‰
    # if len(gate_errors) > 2000:
    #     gate_errors = gate_errors[:2000] + "\n... (truncated)"
    
    evidence_section = f"EVIDENCE:\n{gate_errors}"
    
    # === ç¬¬ 4 æ®µ: AllowedLockedï¼ˆglob/patternsï¼‰===
    allowed_patterns = policy_manager.get_heal_allowed_patterns()
    allowed_paths_str = ", ".join(allowed_patterns) if allowed_patterns else "src/pages/**, src/components/generated/**, src/lib/generated/**"
    
    locked_paths = [
        'package.json', 'vite.config.*', 'src/main.tsx', 
        'src/index.css', 'src/components/ui/*'
    ]
    locked_paths_str = ", ".join(locked_paths)
    
    allowed_locked_section = f"""ALLOWED/LOCKED:
- You MAY ONLY modify files matching: {allowed_paths_str}
- You MUST NOT modify: {locked_paths_str}
- You MUST NOT introduce new dependencies/libraries. Fix ONLY with existing pre-installed libraries (react, date-fns, lucide-react, framer-motion, recharts, etc.). If a chart library is needed, use pure CSS/SVG or the existing implementation."""
    
    # === ç¬¬ 5 æ®µ: OutputContract ===
    output_contract_section = """OUTPUT CONTRACT:
- Output COMPLETE files only (not partial diffs)
- Use this format:
  filename.tsx
  ```
  // ALL imports
  // ALL code
  // ALL styles
  ```
- You must follow BaseRules (see below)"""
    
    # === å¼•ç”¨ BaseRulesï¼ˆä¸å¤åˆ¶ç²˜è´´ï¼‰===
    base_rules_ref = build_base_rules(mode='heal')
    
    # === åŠ¨æ€è§„åˆ™ï¼ˆåŸºäºé—¨ç¦å¤±è´¥æ³¨å…¥ï¼‰===
    dynamic_context = {
        'gate_results': gate_results,
        'files': current_files,
        'prompt_text': '',
        'interaction_spec': interaction_spec
    }
    dynamic_rules, activated_rule_ids = build_dynamic_rules(dynamic_context)
    
    # === Spec è½½è·ï¼ˆç´§å‡‘æ¨¡å¼ï¼Œåªåœ¨éœ€è¦æ—¶ï¼‰===
    spec_section, spec_mode = format_spec_payload(
        interaction_spec, 
        gate_results=gate_results,
        prefer_summary=True
    )
    
    # === æ‹¼æ¥æœ€ç»ˆ promptï¼ˆå›ºå®š 5 æ®µ + BaseRules + DynamicRulesï¼‰===
    prompt = f"""You are an expert code fixer.

{goal_section}

{failed_gates_section}

{evidence_section}

{allowed_locked_section}

{output_contract_section}

================================================================================
{base_rules_ref}

{dynamic_rules}

{spec_section}

Fix the issues now (output COMPLETE modified files):"""
    
    return prompt, activated_rule_ids


def should_trigger_self_heal(gate_results: Dict[str, GateResult]) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘è‡ªæ„ˆå¾ªç¯
    
    Args:
        gate_results: é—¨ç¦ç»“æœ
        
    Returns:
        æ˜¯å¦åº”è¯¥è§¦å‘è‡ªæ„ˆ
    """
    if not policy_manager.is_self_heal_enabled():
        return False
    
    # å¦‚æœæœ‰ä»»ä½•é—¨ç¦å¤±è´¥ï¼Œè§¦å‘è‡ªæ„ˆ
    return any(not result.passed for result in gate_results.values())


def self_heal_loop(
    ai,
    initial_files: Dict[str, str],
    gate_results: Dict[str, GateResult],
    interaction_spec: Dict[str, Any] = None
) -> Tuple[Dict[str, str], bool, int]:
    """
    æ‰§è¡Œè‡ªæ„ˆå¾ªç¯
    
    Args:
        ai: AI å®ä¾‹
        initial_files: åˆå§‹æ–‡ä»¶
        gate_results: åˆå§‹é—¨ç¦ç»“æœ
        interaction_spec: InteractionSpec
        
    Returns:
        (final_files, success, iteration_count)
    """
    from datetime import datetime
    
    max_iterations = policy_manager.get_max_heal_iterations()
    
    current_files = dict(initial_files)
    current_gate_results = gate_results
    
    # ğŸ†• åˆå§‹åŒ–æ²»æ„ˆå†å²è®°å½•
    healing_history = []
    prev_issue_count = sum(len(r.issues) for r in gate_results.values() if not r.passed)
    
    for iteration in range(max_iterations):
        if not should_trigger_self_heal(current_gate_results):
            print(f"   âœ“ è¿­ä»£ {iteration}: æ‰€æœ‰é—¨ç¦é€šè¿‡ï¼Œè‡ªæ„ˆæˆåŠŸ")
            return current_files, True, iteration
        
        print(f"   ğŸ”§ è¿­ä»£ {iteration + 1}/{max_iterations}: å¼€å§‹ä¿®å¤...")
        
        # æ„å»ºä¿®å¤ prompt
        heal_prompt, activated_rule_ids = build_heal_prompt(
            current_gate_results,
            interaction_spec,
            current_files,
            iteration
        )
        
        # è®°å½• telemetry
        log_prompt_telemetry(
            prompt=heal_prompt,
            mode='heal',
            activated_fragments=activated_rule_ids,
            spec_mode='auto',
            context={
                'policy_version': get_policy_version(),
                'iteration': iteration + 1,
                'max_iterations': max_iterations
            }
        )
        
        # è°ƒç”¨ AI ä¿®å¤
        try:
            messages = ai.next(
                messages=[HumanMessage(content=heal_prompt)],
                step_name=f"self_heal_iteration_{iteration + 1}"
            )
            
            # è·å– AI çš„å“åº”
            fixed_code = messages[-1].content
            
            # è§£æä¿®å¤åçš„æ–‡ä»¶
            # ä½¿ç”¨ä¸ gen_code ç›¸åŒçš„è§£æé€»è¾‘
            from gpt_engineer.core.chat_to_files import chat_to_files_dict
            
            fixed_files_dict = chat_to_files_dict(fixed_code)
            
            print(f"     ğŸ“ AI è¿”å›äº† {len(fixed_files_dict)} ä¸ªæ–‡ä»¶")
            
            if not fixed_files_dict:
                print(f"     âš ï¸  è¿­ä»£ {iteration + 1}: AI æœªè¿”å›æœ‰æ•ˆæ–‡ä»¶ï¼Œè·³è¿‡")
                continue
            
            # æ£€æŸ¥ä¿®æ”¹çš„æ–‡ä»¶æ•°é‡
            if len(fixed_files_dict) > policy_manager.get_max_files_per_iteration():
                print(
                    f"     âš ï¸  è¿­ä»£ {iteration + 1}: AI ä¿®æ”¹äº† {len(fixed_files_dict)} ä¸ªæ–‡ä»¶ï¼Œ"
                    f"è¶…è¿‡é™åˆ¶ {policy_manager.get_max_files_per_iteration()}ï¼Œæˆªæ–­"
                )
                # åªä¿ç•™å‰ N ä¸ªæ–‡ä»¶
                fixed_files_dict = dict(list(fixed_files_dict.items())[:policy_manager.get_max_files_per_iteration()])
            
            # åˆå¹¶ä¿®å¤åçš„æ–‡ä»¶ï¼ˆå¸¦è·¯å¾„è¿‡æ»¤ï¼‰
            # ğŸ†• æ”¶é›†æ²»æ„ˆè¡Œä¸ºä¿¡æ¯
            allowed_patterns = policy_manager.get_heal_allowed_patterns()
            filtered_count = 0
            filtered_paths = []
            files_modified = []
            
            for filename, content in fixed_files_dict.items():
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å…è®¸ä¿®æ”¹çš„èŒƒå›´å†…
                is_allowed = False
                if allowed_patterns:
                    for pattern in allowed_patterns:
                        if fnmatch.fnmatch(filename, pattern):
                            is_allowed = True
                            break
                else:
                    # å¦‚æœæ²¡æœ‰é…ç½® allowed_patternsï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™
                    is_allowed = any(filename.startswith(prefix) for prefix in [
                        'src/pages/', 'src/components/generated/', 'src/lib/generated/'
                    ])
                
                if is_allowed:
                    old_content = current_files.get(filename, "")
                    current_files[filename] = content
                    
                    # ğŸ†• è®°å½•æ–‡ä»¶ä¿®æ”¹è¯¦æƒ…
                    is_new = filename not in initial_files and old_content == ""
                    is_changed = old_content != content
                    
                    file_change_record = {
                        "path": filename,
                        "action": "created" if is_new else ("modified" if is_changed else "unchanged"),
                        "size_before": len(old_content),
                        "size_after": len(content),
                        "lines_before": old_content.count('\n') + 1 if old_content else 0,
                        "lines_after": content.count('\n') + 1 if content else 0
                    }
                    files_modified.append(file_change_record)
                    
                    # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ–‡ä»¶æ˜¯å¦çœŸæ­£è¢«ä¿®æ”¹
                    if is_changed:
                        print(f"     âœ“ ä¿®å¤äº†: {filename} (å†…å®¹å·²æ›´æ–°, {len(content)} å­—ç¬¦)")
                    else:
                        print(f"     âš ï¸  ä¿®å¤äº†: {filename} (å†…å®¹æœªå˜åŒ–)")
                else:
                    filtered_count += 1
                    filtered_paths.append(filename)
                    print(f"     âœ— è·³è¿‡ï¼ˆè¶…å‡ºå…è®¸èŒƒå›´ï¼‰: {filename}")
            
            if filtered_count > 0:
                print(f"     âš ï¸  è¿‡æ»¤äº† {filtered_count} ä¸ªè¶…å‡ºå…è®¸èŒƒå›´çš„æ–‡ä»¶ä¿®æ”¹")
            
            # === ä¾èµ–æ£€æµ‹ä¸ä»²è£ï¼ˆé˜²æ­¢è‡ªæ„ˆå¼•å…¥æœªæˆæƒä¾èµ–ï¼‰===
            try:
                detected_deps = detect_dependencies_in_files(current_files)
                if detected_deps:
                    arbiter = DependencyArbiter()
                    dep_report = arbiter.arbitrate(detected_deps)
                    
                    # æ›´æ–° vibe.meta.json
                    if 'vibe.meta.json' in current_files:
                        try:
                            vibe_meta = json.loads(current_files['vibe.meta.json'])
                            vibe_meta['dependencies'] = dep_report
                            current_files['vibe.meta.json'] = json.dumps(vibe_meta, indent=2)
                            print(f"     ğŸ“¦ æ›´æ–°ä¾èµ–æŠ¥å‘Š: {len(dep_report.get('approved', []))} ä¸ªæ‰¹å‡†")
                        except json.JSONDecodeError:
                            pass
            except Exception as dep_err:
                print(f"     âš ï¸  ä¾èµ–æ£€æµ‹è·³è¿‡: {dep_err}")
            
            # é‡æ–°è¿è¡Œé—¨ç¦ï¼ˆåªè¿è¡Œ L0ï¼Œä¸é‡è£…ä¾èµ–ï¼‰
            print(f"   ğŸš¦ è¿­ä»£ {iteration + 1}: é‡æ–°è¿è¡Œé—¨ç¦...")
            current_gate_results = run_quality_gates(current_files)
            
            # ğŸ†• è®°å½•æœ¬è½®è´¨é‡é—¨ç»“æœåˆ°æ²»æ„ˆå†å²
            current_issue_count = sum(len(r.issues) for r in current_gate_results.values() if not r.passed)
            is_regression = current_issue_count > prev_issue_count
            
            iteration_record = {
                "iteration": iteration + 1,
                "timestamp": datetime.now().isoformat(),
                "issues_count": current_issue_count,
                "regression": is_regression,
                # ğŸ†• æ²»æ„ˆè¡Œä¸ºè®°å½•ï¼ˆè®°å½•AIä¿®æ”¹äº†å“ªäº›æ–‡ä»¶ï¼‰
                "healing_actions": {
                    "ai_returned_files": len(fixed_files_dict),
                    "files_applied": len(files_modified),
                    "files_filtered": filtered_count,
                    "filtered_paths": filtered_paths,
                    "changes": files_modified  # æ¯ä¸ªæ–‡ä»¶çš„ä¿®æ”¹è¯¦æƒ…
                },
                "gates": {
                    gate_name: {
                        "passed": result.passed,
                        "issues_count": len(result.issues),
                        "issues": [
                            {
                                "rule_id": issue.get('rule_id'),
                                "severity": issue.get('severity'),
                                "file": issue.get('file'),
                                "message": issue.get('message')
                            }
                            for issue in result.issues  # ğŸ”§ ç§»é™¤æˆªæ–­é™åˆ¶ï¼Œè®°å½•æ‰€æœ‰é—®é¢˜
                        ]
                    }
                    for gate_name, result in current_gate_results.items()
                }
            }
            healing_history.append(iteration_record)
            
            # æ›´æ–° vibe.meta.json çš„ quality_gates å­—æ®µ
            if 'vibe.meta.json' in current_files:
                try:
                    vibe_meta = json.loads(current_files['vibe.meta.json'])
                    if 'quality_gates' not in vibe_meta:
                        vibe_meta['quality_gates'] = {}
                    
                    vibe_meta['quality_gates']['healing_history'] = healing_history
                    vibe_meta['quality_gates']['final'] = {
                        gate_name: result.to_dict()
                        for gate_name, result in current_gate_results.items()
                    }
                    current_files['vibe.meta.json'] = json.dumps(vibe_meta, indent=2)
                    print(f"     ğŸ“Š æ›´æ–°è´¨é‡é—¨å†å²: è¿­ä»£ {iteration + 1}, {current_issue_count} ä¸ªé—®é¢˜" + (" [å›å½’âš ï¸]" if is_regression else ""))
                except json.JSONDecodeError:
                    print(f"     âš ï¸  æ— æ³•æ›´æ–° vibe.meta.json: JSON è§£æå¤±è´¥")
            
            # æ£€æŸ¥æ˜¯å¦é€šè¿‡
            failed_count = sum(1 for r in current_gate_results.values() if not r.passed)
            if failed_count == 0:
                print(f"   âœ“ è¿­ä»£ {iteration + 1}: æ‰€æœ‰é—¨ç¦é€šè¿‡ï¼")
                return current_files, True, iteration + 1
            else:
                print(f"   âš ï¸  è¿­ä»£ {iteration + 1}: ä»æœ‰ {failed_count} ä¸ªé—¨ç¦å¤±è´¥")
                
                # ğŸ†• æ£€æµ‹å›å½’ï¼Œè€ƒè™‘æ˜¯å¦å›æ»šæˆ–æå‰ç»ˆæ­¢
                if is_regression:
                    print(f"   ğŸš¨ æ£€æµ‹åˆ°å›å½’ï¼šé—®é¢˜æ•°ä» {prev_issue_count} å¢åŠ åˆ° {current_issue_count}")
                    # æš‚ä¸å›æ»šï¼Œç»§ç»­å°è¯•ï¼ˆå¯ä»¥æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
                
                prev_issue_count = current_issue_count
        
        except Exception as e:
            print(f"   âœ— è¿­ä»£ {iteration + 1}: ä¿®å¤å¤±è´¥ - {str(e)}")
            continue
    
    # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œä»æœªé€šè¿‡
    print(f"   âœ— è‡ªæ„ˆå¤±è´¥ï¼šå·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}")
    
    # ğŸ†• ç¡®ä¿æœ€ç»ˆçŠ¶æ€è¢«è®°å½•åˆ° vibe.meta.json
    if 'vibe.meta.json' in current_files and healing_history:
        try:
            vibe_meta = json.loads(current_files['vibe.meta.json'])
            if 'quality_gates' not in vibe_meta:
                vibe_meta['quality_gates'] = {}
            
            vibe_meta['quality_gates']['healing_history'] = healing_history
            vibe_meta['quality_gates']['final'] = {
                gate_name: result.to_dict()
                for gate_name, result in current_gate_results.items()
            }
            current_files['vibe.meta.json'] = json.dumps(vibe_meta, indent=2)
        except json.JSONDecodeError:
            pass
    
    return current_files, False, max_iterations

