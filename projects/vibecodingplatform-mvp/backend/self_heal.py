"""
è‡ªæ„ˆå¾ªç¯ - è‡ªåŠ¨ä¿®å¤è´¨é‡é—¨ç¦å¤±è´¥çš„ä»£ç 
"""
import json
import fnmatch
from typing import Dict, Any, Tuple, List
from policies import policy_manager
from quality_gates import run_quality_gates, format_gate_results_for_heal, GateResult
from langchain_core.messages import HumanMessage
from prompt_fragments import (
    build_base_rules,
    build_dynamic_rules,
    format_spec_payload,
    get_policy_version,
    log_prompt_telemetry,
    compute_prompt_hash
)
from dependency_detector import detect_dependencies_in_files
from dependency_arbiter import DependencyArbiter


def count_errors(gate_results: Dict[str, GateResult]) -> int:
    """
    åªç»Ÿè®¡ L0_static çš„ errorï¼Œä¸è®¡ warning
    ä¸é—¨ç¦ passed è¯­ä¹‰ä¿æŒä¸€è‡´
    """
    if "L0_static" in gate_results:
        result = gate_results["L0_static"]
        return len([i for i in result.issues if i.get('severity') == 'error'])
    
    # é€€åŒ–ï¼šå…¨é‡ç»Ÿè®¡
    return sum(
        len([i for i in r.issues if i.get('severity') == 'error'])
        for r in gate_results.values()
    )


def count_total_issues(gate_results: Dict[str, GateResult]) -> int:
    """ç»Ÿè®¡æ‰€æœ‰ issuesï¼ˆç”¨äº warning çˆ†ç‚¸ä¿æŠ¤ï¼‰"""
    return sum(len(r.issues) for r in gate_results.values())


def should_accept_debt(gate_results: Dict[str, GateResult]) -> Tuple[bool, str]:
    """
    å½“ä»…å‰© data_contract é—®é¢˜ä¸” TypeCheck é€šè¿‡æ—¶ï¼Œå…è®¸æ¥å—å€ºåŠ¡ç»“æŸ
    """
    errors = [
        i for r in gate_results.values() 
        for i in r.issues 
        if i.get('severity') == 'error'
    ]
    
    if not errors:
        return True, "no_errors"
    
    non_data_contract_errors = [
        e for e in errors 
        if e.get('rule_id') != 'data_contract_violation'
    ]
    
    # ä»…å‰© data_contract ä¸” TypeCheck é€šè¿‡
    typecheck_passed = gate_results.get("L1_typecheck", GateResult('L1_typecheck', True)).passed
    if not non_data_contract_errors and typecheck_passed:
        return True, "data_contract_debt_accepted"
    
    return False, ""


def build_heal_prompt(
    gate_results: Dict[str, GateResult],
    interaction_spec: Dict[str, Any],
    current_files: Dict[str, str],
    iteration: int
) -> tuple[str, List[str]]:
    """
    æ„å»ºè‡ªæ„ˆä¿®å¤çš„ promptï¼ˆå›ºå®š 5 æ®µæ¨¡æ¿ï¼‰
    
    Args:
        gate_results: é—¨ç¦ç»“æœ
        interaction_spec: InteractionSpec
        current_files: å½“å‰æ–‡ä»¶
        iteration: å½“å‰è¿­ä»£æ¬¡æ•°
        
    Returns:
        (ä¿®å¤ prompt, æ¿€æ´»çš„åŠ¨æ€è§„åˆ™ IDs)
    """
    # === ç¬¬ 1 æ®µ: Goal ===
    goal_section = f"""GOAL: Fix quality gate failures and keep application runnable.
Iteration {iteration + 1}/{policy_manager.get_max_heal_iterations()}"""
    
    # === ç¬¬ 2 æ®µ: FailedGatesï¼ˆçŸ­åˆ—è¡¨ï¼‰===
    failed_gates = []
    for gate_name, result in gate_results.items():
        if not result.passed:
            issue_count = len(result.issues)
            failed_gates.append(f"  - {gate_name}: {issue_count} issues")
    
    failed_gates_section = "FAILED GATES:\n" + "\n".join(failed_gates)
    
    # === ç¬¬ 3 æ®µ: Evidenceï¼ˆé—¨ç¦è¯æ®ï¼Œä¼˜åŒ–åä¸éœ€è¦æˆªæ–­ï¼‰===
    gate_errors = format_gate_results_for_heal(
        gate_results, 
        max_issues=8,  # é™åˆ¶ä¸º8ä¸ªæœ€é‡è¦çš„é—®é¢˜
        group_by_file=True  # æŒ‰æ–‡ä»¶åˆ†ç»„
    )
    
    # ç§»é™¤æ—§çš„æˆªæ–­é€»è¾‘ï¼ˆæ–°æ–¹æ³•å·²å†…ç½®æ™ºèƒ½é™åˆ¶ï¼‰
    # if len(gate_errors) > 2000:
    #     gate_errors = gate_errors[:2000] + "\n... (truncated)"
    
    evidence_section = f"EVIDENCE:\n{gate_errors}"
    
    # === ç¬¬ 4 æ®µ: AllowedLockedï¼ˆglob/patternsï¼‰===
    allowed_patterns = policy_manager.get_heal_allowed_patterns()
    allowed_paths_str = ", ".join(allowed_patterns) if allowed_patterns else "src/pages/**, src/components/generated/**, src/lib/generated/**"
    
    locked_paths = [
        'package.json', 'vite.config.*', 'src/main.tsx', 
        'src/index.css', 'src/components/ui/*'
    ]
    locked_paths_str = ", ".join(locked_paths)
    
    allowed_locked_section = f"""ALLOWED/LOCKED:
- You MAY ONLY modify files matching: {allowed_paths_str}
- You MUST NOT modify: {locked_paths_str}
- You MUST NOT introduce new dependencies/libraries. Fix ONLY with existing pre-installed libraries (react, date-fns, lucide-react, framer-motion, recharts, etc.). If a chart library is needed, use pure CSS/SVG or the existing implementation.

CRITICAL - Do NOT refactor or restructure code:
- Fix ONLY the specific issues listed in EVIDENCE
- Do NOT rename exports/imports unless fixing a mismatch
- Do NOT change function signatures
- Do NOT reorganize file structure
- Do NOT add new features or abstractions
- MINIMIZE the scope of changes to only what's necessary to pass the gates"""
    
    # === ç¬¬ 5 æ®µ: OutputContract ===
    output_contract_section = """OUTPUT CONTRACT:
- Output COMPLETE files only (not partial diffs)
- Use this format:
  filename.tsx
  ```
  // ALL imports
  // ALL code
  // ALL styles
  ```
- You must follow BaseRules (see below)"""
    
    # === å¼•ç”¨ BaseRulesï¼ˆä¸å¤åˆ¶ç²˜è´´ï¼‰===
    base_rules_ref = build_base_rules(mode='heal')
    
    # === åŠ¨æ€è§„åˆ™ï¼ˆåŸºäºé—¨ç¦å¤±è´¥æ³¨å…¥ï¼‰===
    dynamic_context = {
        'gate_results': gate_results,
        'files': current_files,
        'prompt_text': '',
        'interaction_spec': interaction_spec
    }
    dynamic_rules, activated_rule_ids = build_dynamic_rules(dynamic_context)
    
    # === Spec è½½è·ï¼ˆç´§å‡‘æ¨¡å¼ï¼Œåªåœ¨éœ€è¦æ—¶ï¼‰===
    spec_section, spec_mode = format_spec_payload(
        interaction_spec, 
        gate_results=gate_results,
        prefer_summary=True
    )
    
    # === æ‹¼æ¥æœ€ç»ˆ promptï¼ˆå›ºå®š 5 æ®µ + BaseRules + DynamicRulesï¼‰===
    prompt = f"""You are an expert code fixer.

{goal_section}

{failed_gates_section}

{evidence_section}

{allowed_locked_section}

{output_contract_section}

================================================================================
{base_rules_ref}

{dynamic_rules}

{spec_section}

Fix the issues now (output COMPLETE modified files):"""
    
    return prompt, activated_rule_ids


def should_trigger_self_heal(gate_results: Dict[str, GateResult]) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘è‡ªæ„ˆå¾ªç¯
    
    Args:
        gate_results: é—¨ç¦ç»“æœ
        
    Returns:
        æ˜¯å¦åº”è¯¥è§¦å‘è‡ªæ„ˆ
    """
    if not policy_manager.is_self_heal_enabled():
        return False
    
    # å¦‚æœæœ‰ä»»ä½•é—¨ç¦å¤±è´¥ï¼Œè§¦å‘è‡ªæ„ˆ
    return any(not result.passed for result in gate_results.values())


def self_heal_loop(
    ai,
    initial_files: Dict[str, str],
    gate_results: Dict[str, GateResult],
    interaction_spec: Dict[str, Any] = None
) -> Tuple[Dict[str, str], bool, int]:
    """
    æ‰§è¡Œè‡ªæ„ˆå¾ªç¯
    
    Args:
        ai: AI å®ä¾‹
        initial_files: åˆå§‹æ–‡ä»¶
        gate_results: åˆå§‹é—¨ç¦ç»“æœ
        interaction_spec: InteractionSpec
        
    Returns:
        (final_files, success, iteration_count)
    """
    from datetime import datetime
    
    max_iterations = policy_manager.get_max_heal_iterations()
    
    current_files = dict(initial_files)
    current_gate_results = gate_results
    
    # ğŸ†• åˆå§‹åŒ– best snapshot æœºåˆ¶
    best_snapshot = {
        "files": current_files.copy(),
        "gate_results": current_gate_results,
        "error_count": count_errors(current_gate_results),
        "total_count": count_total_issues(current_gate_results),
        "iteration": 0
    }
    
    # ğŸ†• åˆå§‹åŒ–æ²»æ„ˆå†å²è®°å½•
    healing_history = []
    
    # åŠ¨æ€è°ƒæ•´ max_files
    initial_max_files = policy_manager.get_max_files_per_iteration()
    max_files_this_iteration = initial_max_files
    regression_count = 0
    WARNING_EXPLOSION_THRESHOLD = 10
    
    for iteration in range(max_iterations):
        # æ£€æŸ¥æ¥å—å€ºåŠ¡
        can_accept, reason = should_accept_debt(current_gate_results)
        if can_accept:
            print(f"   âœ… æ¥å—å€ºåŠ¡ç»“æŸï¼š{reason}")
            return current_files, True, iteration
        
        if not should_trigger_self_heal(current_gate_results):
            print(f"   âœ“ è¿­ä»£ {iteration}: æ‰€æœ‰é—¨ç¦é€šè¿‡ï¼Œè‡ªæ„ˆæˆåŠŸ")
            return current_files, True, iteration
        
        # ä¿å­˜ previous çŠ¶æ€
        previous_files = current_files.copy()
        previous_error_count = count_errors(current_gate_results)
        previous_total_count = count_total_issues(current_gate_results)
        
        print(f"   ğŸ”§ è¿­ä»£ {iteration + 1}/{max_iterations}: å¼€å§‹ä¿®å¤...")
        
        # æ„å»ºä¿®å¤ prompt
        heal_prompt, activated_rule_ids = build_heal_prompt(
            current_gate_results,
            interaction_spec,
            current_files,
            iteration
        )
        
        # è®°å½• telemetry
        log_prompt_telemetry(
            prompt=heal_prompt,
            mode='heal',
            activated_fragments=activated_rule_ids,
            spec_mode='auto',
            context={
                'policy_version': get_policy_version(),
                'iteration': iteration + 1,
                'max_iterations': max_iterations
            }
        )
        
        # è°ƒç”¨ AI ä¿®å¤
        try:
            messages = ai.next(
                messages=[HumanMessage(content=heal_prompt)],
                step_name=f"self_heal_iteration_{iteration + 1}"
            )
            
            # è·å– AI çš„å“åº”
            fixed_code = messages[-1].content
            
            # è§£æä¿®å¤åçš„æ–‡ä»¶
            # ä½¿ç”¨ä¸ gen_code ç›¸åŒçš„è§£æé€»è¾‘
            from gpt_engineer.core.chat_to_files import chat_to_files_dict
            
            fixed_files_dict = chat_to_files_dict(fixed_code)
            
            print(f"     ğŸ“ AI è¿”å›äº† {len(fixed_files_dict)} ä¸ªæ–‡ä»¶")
            
            if not fixed_files_dict:
                print(f"     âš ï¸  è¿­ä»£ {iteration + 1}: AI æœªè¿”å›æœ‰æ•ˆæ–‡ä»¶ï¼Œè·³è¿‡")
                continue
            
            # æ£€æŸ¥ä¿®æ”¹çš„æ–‡ä»¶æ•°é‡ï¼ˆä½¿ç”¨åŠ¨æ€é™åˆ¶ï¼‰
            if len(fixed_files_dict) > max_files_this_iteration:
                print(
                    f"     âš ï¸  è¿­ä»£ {iteration + 1}: AI ä¿®æ”¹äº† {len(fixed_files_dict)} ä¸ªæ–‡ä»¶ï¼Œ"
                    f"è¶…è¿‡é™åˆ¶ {max_files_this_iteration}ï¼Œæˆªæ–­"
                )
                # åªä¿ç•™å‰ N ä¸ªæ–‡ä»¶
                fixed_files_dict = dict(list(fixed_files_dict.items())[:max_files_this_iteration])
            
            # åˆå¹¶ä¿®å¤åçš„æ–‡ä»¶ï¼ˆå¸¦è·¯å¾„è¿‡æ»¤ï¼‰
            # ğŸ†• æ”¶é›†æ²»æ„ˆè¡Œä¸ºä¿¡æ¯
            allowed_patterns = policy_manager.get_heal_allowed_patterns()
            filtered_count = 0
            filtered_paths = []
            files_modified = []
            
            for filename, content in fixed_files_dict.items():
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å…è®¸ä¿®æ”¹çš„èŒƒå›´å†…
                is_allowed = False
                if allowed_patterns:
                    for pattern in allowed_patterns:
                        if fnmatch.fnmatch(filename, pattern):
                            is_allowed = True
                            break
                else:
                    # å¦‚æœæ²¡æœ‰é…ç½® allowed_patternsï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™
                    is_allowed = any(filename.startswith(prefix) for prefix in [
                        'src/pages/', 'src/components/generated/', 'src/lib/generated/'
                    ])
                
                if is_allowed:
                    old_content = current_files.get(filename, "")
                    current_files[filename] = content
                    
                    # ğŸ†• è®°å½•æ–‡ä»¶ä¿®æ”¹è¯¦æƒ…
                    is_new = filename not in initial_files and old_content == ""
                    is_changed = old_content != content
                    
                    file_change_record = {
                        "path": filename,
                        "action": "created" if is_new else ("modified" if is_changed else "unchanged"),
                        "size_before": len(old_content),
                        "size_after": len(content),
                        "lines_before": old_content.count('\n') + 1 if old_content else 0,
                        "lines_after": content.count('\n') + 1 if content else 0
                    }
                    files_modified.append(file_change_record)
                    
                    # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ–‡ä»¶æ˜¯å¦çœŸæ­£è¢«ä¿®æ”¹
                    if is_changed:
                        print(f"     âœ“ ä¿®å¤äº†: {filename} (å†…å®¹å·²æ›´æ–°, {len(content)} å­—ç¬¦)")
                    else:
                        print(f"     âš ï¸  ä¿®å¤äº†: {filename} (å†…å®¹æœªå˜åŒ–)")
                else:
                    filtered_count += 1
                    filtered_paths.append(filename)
                    print(f"     âœ— è·³è¿‡ï¼ˆè¶…å‡ºå…è®¸èŒƒå›´ï¼‰: {filename}")
            
            if filtered_count > 0:
                print(f"     âš ï¸  è¿‡æ»¤äº† {filtered_count} ä¸ªè¶…å‡ºå…è®¸èŒƒå›´çš„æ–‡ä»¶ä¿®æ”¹")
            
            # === ä¾èµ–æ£€æµ‹ä¸ä»²è£ï¼ˆé˜²æ­¢è‡ªæ„ˆå¼•å…¥æœªæˆæƒä¾èµ–ï¼‰===
            try:
                detected_deps = detect_dependencies_in_files(current_files)
                if detected_deps:
                    arbiter = DependencyArbiter()
                    dep_report = arbiter.arbitrate(detected_deps)
                    
                    # æ›´æ–° vibe.meta.json
                    if 'vibe.meta.json' in current_files:
                        try:
                            vibe_meta = json.loads(current_files['vibe.meta.json'])
                            vibe_meta['dependencies'] = dep_report
                            current_files['vibe.meta.json'] = json.dumps(vibe_meta, indent=2)
                            print(f"     ğŸ“¦ æ›´æ–°ä¾èµ–æŠ¥å‘Š: {len(dep_report.get('approved', []))} ä¸ªæ‰¹å‡†")
                        except json.JSONDecodeError:
                            pass
            except Exception as dep_err:
                print(f"     âš ï¸  ä¾èµ–æ£€æµ‹è·³è¿‡: {dep_err}")
            
            # é‡æ–°è¿è¡Œé—¨ç¦ï¼ˆåªè¿è¡Œ L0ï¼Œä¸é‡è£…ä¾èµ–ï¼‰
            print(f"   ğŸš¦ è¿­ä»£ {iteration + 1}: é‡æ–°è¿è¡Œé—¨ç¦...")
            new_gate_results = run_quality_gates(current_files)
            current_gate_results = new_gate_results  # åŒæ­¥æ›´æ–°
            
            # ğŸ†• ç»Ÿè®¡ error å’Œ total issues
            current_error_count = count_errors(current_gate_results)
            current_total_count = count_total_issues(current_gate_results)
            
            # æ›´æ–° best snapshotï¼ˆerror æœ€å°‘ â†’ total æœ€å°‘ï¼‰
            is_better = (
                current_error_count < best_snapshot["error_count"] or
                (current_error_count == best_snapshot["error_count"] and 
                 current_total_count < best_snapshot["total_count"])
            )
            if is_better:
                best_snapshot = {
                    "files": current_files.copy(),
                    "gate_results": current_gate_results,
                    "error_count": current_error_count,
                    "total_count": current_total_count,
                    "iteration": iteration + 1
                }
                print(f"     ğŸ“Œ æ›´æ–° best_snapshot: {current_error_count} errors, {current_total_count} total")
            
            # åˆ¤æ–­ regression
            is_hard_regression = current_error_count > previous_error_count
            is_soft_regression = (
                current_error_count <= previous_error_count and
                current_total_count > previous_total_count + WARNING_EXPLOSION_THRESHOLD
            )
            is_regression = is_hard_regression or is_soft_regression
            
            iteration_record = {
                "iteration": iteration + 1,
                "timestamp": datetime.now().isoformat(),
                "error_count": current_error_count,
                "total_count": current_total_count,
                "regression": is_regression,
                "regression_type": "hard" if is_hard_regression else ("soft" if is_soft_regression else "none"),
                # ğŸ†• æ²»æ„ˆè¡Œä¸ºè®°å½•ï¼ˆè®°å½•AIä¿®æ”¹äº†å“ªäº›æ–‡ä»¶ï¼‰
                "healing_actions": {
                    "ai_returned_files": len(fixed_files_dict),
                    "files_applied": len(files_modified),
                    "files_filtered": filtered_count,
                    "filtered_paths": filtered_paths,
                    "max_files_limit": max_files_this_iteration,
                    "changes": files_modified  # æ¯ä¸ªæ–‡ä»¶çš„ä¿®æ”¹è¯¦æƒ…
                },
                "gates": {
                    gate_name: {
                        "passed": result.passed,
                        "issues_count": len(result.issues),
                        "issues": [
                            {
                                "rule_id": issue.get('rule_id'),
                                "severity": issue.get('severity'),
                                "file": issue.get('file'),
                                "message": issue.get('message')
                            }
                            for issue in result.issues  # ğŸ”§ ç§»é™¤æˆªæ–­é™åˆ¶ï¼Œè®°å½•æ‰€æœ‰é—®é¢˜
                        ]
                    }
                    for gate_name, result in current_gate_results.items()
                }
            }
            healing_history.append(iteration_record)
            
            # æ›´æ–° vibe.meta.json çš„ quality_gates å­—æ®µ
            if 'vibe.meta.json' in current_files:
                try:
                    vibe_meta = json.loads(current_files['vibe.meta.json'])
                    if 'quality_gates' not in vibe_meta:
                        vibe_meta['quality_gates'] = {}
                    
                    vibe_meta['quality_gates']['healing_history'] = healing_history
                    vibe_meta['quality_gates']['final'] = {
                        gate_name: result.to_dict()
                        for gate_name, result in current_gate_results.items()
                    }
                    current_files['vibe.meta.json'] = json.dumps(vibe_meta, indent=2)
                    print(f"     ğŸ“Š æ›´æ–°è´¨é‡é—¨å†å²: è¿­ä»£ {iteration + 1}, {current_total_count} ä¸ªé—®é¢˜" + (" [å›å½’âš ï¸]" if is_regression else ""))
                except json.JSONDecodeError:
                    print(f"     âš ï¸  æ— æ³•æ›´æ–° vibe.meta.json: JSON è§£æå¤±è´¥")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å›æ»š
            if is_regression:
                regression_type = "hard" if is_hard_regression else "soft(warningçˆ†ç‚¸)"
                print(f"     âš ï¸  {regression_type} regression: {previous_error_count} â†’ {current_error_count} errors")
                current_files = previous_files
                current_gate_results = run_quality_gates(current_files)  # åŒæ­¥
                regression_count += 1
                
                if regression_count >= 2:
                    print(f"     âŒ è¿ç»­ regressionï¼Œè¾“å‡º best_snapshot (iteration {best_snapshot['iteration']})")
                    current_files = best_snapshot["files"]
                    current_gate_results = best_snapshot["gate_results"]
                    break
                
                # å›æ»šåæ”¶ç´§ç­–ç•¥
                max_files_this_iteration = 1
                print(f"     â†“ max_files æ”¶ç´§åˆ° {max_files_this_iteration}")
                continue
            
            # æˆåŠŸåé€æ­¥æ¢å¤ max_files
            if max_files_this_iteration < initial_max_files:
                max_files_this_iteration = min(max_files_this_iteration + 2, initial_max_files)
                print(f"     â†‘ max_files æ¢å¤åˆ° {max_files_this_iteration}")
            regression_count = 0  # é‡ç½®è¿ç»­ regression è®¡æ•°
            
            # æ£€æŸ¥æ˜¯å¦é€šè¿‡
            failed_count = sum(1 for r in current_gate_results.values() if not r.passed)
            if failed_count == 0:
                print(f"   âœ“ è¿­ä»£ {iteration + 1}: æ‰€æœ‰é—¨ç¦é€šè¿‡ï¼")
                return current_files, True, iteration + 1
            else:
                print(f"   âš ï¸  è¿­ä»£ {iteration + 1}: ä»æœ‰ {failed_count} ä¸ªé—¨ç¦å¤±è´¥")
        
        except Exception as e:
            print(f"   âœ— è¿­ä»£ {iteration + 1}: ä¿®å¤å¤±è´¥ - {str(e)}")
            continue
    
    # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œä»æœªé€šè¿‡
    print(f"   âœ— è‡ªæ„ˆå¤±è´¥ï¼šå·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}")
    
    # æœ€ç»ˆè¾“å‡º bestï¼ˆå¦‚æœå½“å‰ä¸æ˜¯ bestï¼‰
    final_error_count = count_errors(current_gate_results)
    if final_error_count > best_snapshot["error_count"]:
        print(f"   ğŸ“Œ è¾“å‡º best_snapshot (iteration {best_snapshot['iteration']}): {best_snapshot['error_count']} errors")
        current_files = best_snapshot["files"]
        current_gate_results = best_snapshot["gate_results"]
    
    # ğŸ†• ç¡®ä¿æœ€ç»ˆçŠ¶æ€è¢«è®°å½•åˆ° vibe.meta.json
    if 'vibe.meta.json' in current_files and healing_history:
        try:
            vibe_meta = json.loads(current_files['vibe.meta.json'])
            if 'quality_gates' not in vibe_meta:
                vibe_meta['quality_gates'] = {}
            
            vibe_meta['quality_gates']['healing_history'] = healing_history
            vibe_meta['quality_gates']['final'] = {
                gate_name: result.to_dict()
                for gate_name, result in current_gate_results.items()
            }
            current_files['vibe.meta.json'] = json.dumps(vibe_meta, indent=2)
        except json.JSONDecodeError:
            pass
    
    return current_files, False, max_iterations

